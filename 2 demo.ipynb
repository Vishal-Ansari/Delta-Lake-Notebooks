{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7134ea8-d291-445a-9676-3bac1b13efb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>key</th><th>value</th></tr></thead><tbody><tr><td>spark.databricks.delta.properties.defaults.autoOptimize.autoCompact</td><td>false</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "spark.databricks.delta.properties.defaults.autoOptimize.autoCompact",
         "false"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "key",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SET spark.databricks.delta.properties.defaults.autoOptimize.optimizeWrite =false;\n",
    "SET spark.databricks.delta.properties.defaults.autoOptimize.autoCompact = false;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afbb9c74-69d6-4992-a733-4996593867a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%python\n",
    "dbutils.fs.rm(\"dbfs:/user/hive/warehouse/demo/\", True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3366bfd0-0664-4cbb-b59d-640dc973ea4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS demo;\n",
    "CREATE TABLE demo \n",
    "(id INT, valid BOOLEAN, name STRING)\n",
    "USING DELTA\n",
    "LOCATION 'dbfs:/user/hive/warehouse/demo/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08da22c0-09f6-48e0-b9d2-2bd5529e9f09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "ALTER TABLE demo ALTER COLUMN valid SET NOT NULL;\n",
    "ALTER TABLE demo ADD CONSTRAINT Ids CHECK (id > 0 AND id < 99999999);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7603f4e8-e76c-492f-8a34-62d533120a1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>id</td><td>int</td><td>null</td></tr><tr><td>valid</td><td>boolean</td><td>null</td></tr><tr><td>name</td><td>string</td><td>null</td></tr><tr><td></td><td></td><td></td></tr><tr><td># Detailed Table Information</td><td></td><td></td></tr><tr><td>Catalog</td><td>spark_catalog</td><td></td></tr><tr><td>Database</td><td>default</td><td></td></tr><tr><td>Table</td><td>demo</td><td></td></tr><tr><td>Created Time</td><td>Mon Feb 03 07:39:17 UTC 2025</td><td></td></tr><tr><td>Last Access</td><td>UNKNOWN</td><td></td></tr><tr><td>Created By</td><td>Spark 3.5.0</td><td></td></tr><tr><td>Type</td><td>EXTERNAL</td><td></td></tr><tr><td>Location</td><td>dbfs:/user/hive/warehouse/demo</td><td></td></tr><tr><td>Provider</td><td>delta</td><td></td></tr><tr><td>Owner</td><td>root</td><td></td></tr><tr><td>Table Properties</td><td>[delta.autoOptimize.autoCompact=false,delta.autoOptimize.optimizeWrite=false,delta.constraints.ids=id > 0 AND id < 99999999,delta.minReaderVersion=1,delta.minWriterVersion=3]</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "id",
         "int",
         null
        ],
        [
         "valid",
         "boolean",
         null
        ],
        [
         "name",
         "string",
         null
        ],
        [
         "",
         "",
         ""
        ],
        [
         "# Detailed Table Information",
         "",
         ""
        ],
        [
         "Catalog",
         "spark_catalog",
         ""
        ],
        [
         "Database",
         "default",
         ""
        ],
        [
         "Table",
         "demo",
         ""
        ],
        [
         "Created Time",
         "Mon Feb 03 07:39:17 UTC 2025",
         ""
        ],
        [
         "Last Access",
         "UNKNOWN",
         ""
        ],
        [
         "Created By",
         "Spark 3.5.0",
         ""
        ],
        [
         "Type",
         "EXTERNAL",
         ""
        ],
        [
         "Location",
         "dbfs:/user/hive/warehouse/demo",
         ""
        ],
        [
         "Provider",
         "delta",
         ""
        ],
        [
         "Owner",
         "root",
         ""
        ],
        [
         "Table Properties",
         "[delta.autoOptimize.autoCompact=false,delta.autoOptimize.optimizeWrite=false,delta.constraints.ids=id > 0 AND id < 99999999,delta.minReaderVersion=1,delta.minWriterVersion=3]",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\":\"name of the column\"}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"data type of the column\"}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"comment of the column\"}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE EXTENDED demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5830b074-8ba9-428f-b047-8466a2d71c63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>format</th><th>id</th><th>name</th><th>description</th><th>location</th><th>createdAt</th><th>lastModified</th><th>partitionColumns</th><th>clusteringColumns</th><th>numFiles</th><th>sizeInBytes</th><th>properties</th><th>minReaderVersion</th><th>minWriterVersion</th><th>tableFeatures</th><th>statistics</th></tr></thead><tbody><tr><td>delta</td><td>0abc6503-7dc5-4e21-bee8-d2bf89a4804f</td><td>spark_catalog.default.demo</td><td>null</td><td>dbfs:/user/hive/warehouse/demo</td><td>2025-02-03T07:39:16.779Z</td><td>2025-02-03T07:39:21Z</td><td>List()</td><td>List()</td><td>0</td><td>0</td><td>Map(delta.autoOptimize.optimizeWrite -> false, delta.autoOptimize.autoCompact -> false, delta.constraints.ids -> id > 0 AND id < 99999999)</td><td>1</td><td>3</td><td>List(appendOnly, checkConstraints, invariants)</td><td>Map()</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "delta",
         "0abc6503-7dc5-4e21-bee8-d2bf89a4804f",
         "spark_catalog.default.demo",
         null,
         "dbfs:/user/hive/warehouse/demo",
         "2025-02-03T07:39:16.779Z",
         "2025-02-03T07:39:21Z",
         [],
         [],
         0,
         0,
         {
          "delta.autoOptimize.autoCompact": "false",
          "delta.autoOptimize.optimizeWrite": "false",
          "delta.constraints.ids": "id > 0 AND id < 99999999"
         },
         1,
         3,
         [
          "appendOnly",
          "checkConstraints",
          "invariants"
         ],
         {}
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "format",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "location",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "createdAt",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "lastModified",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "partitionColumns",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "clusteringColumns",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "numFiles",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "sizeInBytes",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "properties",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "minReaderVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "minWriterVersion",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "tableFeatures",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "statistics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"long\",\"valueContainsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92e2df52-ce93-4f49-a6e6-9540ca152ac9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/</td><td>_delta_log/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/",
         "_delta_log/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c693554-3e6a-49ea-b0cc-a090f67d2a37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc</td><td>00000000000000000000.crc</td><td>2131</td><td>1738568358000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json</td><td>00000000000000000000.json</td><td>1245</td><td>1738568357000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc</td><td>00000000000000000001.crc</td><td>2118</td><td>1738568360000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json</td><td>00000000000000000001.json</td><td>1052</td><td>1738568359000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc</td><td>00000000000000000002.crc</td><td>2183</td><td>1738568362000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json</td><td>00000000000000000002.json</td><td>1120</td><td>1738568361000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/_commits/</td><td>_commits/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc",
         "00000000000000000000.crc",
         2131,
         1738568358000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json",
         "00000000000000000000.json",
         1245,
         1738568357000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc",
         "00000000000000000001.crc",
         2118,
         1738568360000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json",
         "00000000000000000001.json",
         1052,
         1738568359000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc",
         "00000000000000000002.crc",
         2183,
         1738568362000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json",
         "00000000000000000002.json",
         1120,
         1738568361000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/_commits/",
         "_commits/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo/_delta_log/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d365c810-8b5b-4c1f-8ef3-435ea4787bba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##JSON  DELTA LOG FILES\n",
    "Delta Lake stores its transaction log as a series of JSON files in the _delta_log directory of each Delta table. These JSON files record all metadata and schema changes made to the Delta table, including operations like inserts, updates, and deletes. This log enables Delta Lake to support features like ACID transactions, schema evolution, and time travel (i.e., querying historical data versions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6401cb6-7115-4b30-a741-7ab677093125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>commitInfo</th><th>metaData</th><th>protocol</th></tr></thead><tbody><tr><td>List(0203-052121-nggyovx3, Databricks-Runtime/15.4.x-scala2.12, true, WriteSerializable, List(364901121925936), CREATE TABLE, List([], null, false, [], {\"delta.autoOptimize.optimizeWrite\":\"false\",\"delta.autoOptimize.autoCompact\":\"false\"}, false), List(false), 1738568356837, 1a133e42-a30e-4053-930b-7d5328d24296, 5755764547042441, inaya998877@gmail.com)</td><td>null</td><td>null</td></tr><tr><td>null</td><td>List(List(false, false), 1738568356779, List(parquet), 0abc6503-7dc5-4e21-bee8-d2bf89a4804f, List(), {\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]})</td><td>null</td></tr><tr><td>null</td><td>null</td><td>List(1, 2)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "0203-052121-nggyovx3",
          "Databricks-Runtime/15.4.x-scala2.12",
          true,
          "WriteSerializable",
          [
           "364901121925936"
          ],
          "CREATE TABLE",
          [
           "[]",
           null,
           "false",
           "[]",
           "{\"delta.autoOptimize.optimizeWrite\":\"false\",\"delta.autoOptimize.autoCompact\":\"false\"}",
           false
          ],
          [
           "false"
          ],
          1738568356837,
          "1a133e42-a30e-4053-930b-7d5328d24296",
          "5755764547042441",
          "inaya998877@gmail.com"
         ],
         null,
         null
        ],
        [
         null,
         [
          [
           "false",
           "false"
          ],
          1738568356779,
          [
           "parquet"
          ],
          "0abc6503-7dc5-4e21-bee8-d2bf89a4804f",
          [],
          "{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
         ],
         null
        ],
        [
         null,
         null,
         [
          1,
          2
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "commitInfo",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"clusterId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"engineInfo\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"isBlindAppend\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"isolationLevel\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"notebook\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"operation\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"operationParameters\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"clusterBy\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"description\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"isManaged\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"partitionBy\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"properties\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"statsOnLoad\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"tags\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"restoresDeletedRows\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"timestamp\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"txnId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"userId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"userName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "metaData",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"configuration\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"delta.autoOptimize.autoCompact\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"delta.autoOptimize.optimizeWrite\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"createdTime\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"format\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"provider\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"partitionColumns\",\"type\":{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"schemaString\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "protocol",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"minReaderVersion\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"minWriterVersion\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM JSON.`dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29a35d1b-233b-488d-b61f-ef2a5151a610",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>commitInfo</th><th>metaData</th></tr></thead><tbody><tr><td>List(0203-052121-nggyovx3, Databricks-Runtime/15.4.x-scala2.12, false, WriteSerializable, List(364901121925936), CHANGE COLUMN, List({\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":false,\"metadata\":{}}), 0, 1738568358549, cb8a4f23-ad36-4e1c-8bb4-b418ef1d9039, 5755764547042441, inaya998877@gmail.com)</td><td>null</td></tr><tr><td>null</td><td>List(List(false, false), 1738568356779, List(parquet), 0abc6503-7dc5-4e21-bee8-d2bf89a4804f, List(), {\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":false,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]})</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "0203-052121-nggyovx3",
          "Databricks-Runtime/15.4.x-scala2.12",
          false,
          "WriteSerializable",
          [
           "364901121925936"
          ],
          "CHANGE COLUMN",
          [
           "{\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":false,\"metadata\":{}}"
          ],
          0,
          1738568358549,
          "cb8a4f23-ad36-4e1c-8bb4-b418ef1d9039",
          "5755764547042441",
          "inaya998877@gmail.com"
         ],
         null
        ],
        [
         null,
         [
          [
           "false",
           "false"
          ],
          1738568356779,
          [
           "parquet"
          ],
          "0abc6503-7dc5-4e21-bee8-d2bf89a4804f",
          [],
          "{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":false,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "commitInfo",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"clusterId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"engineInfo\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"isBlindAppend\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"isolationLevel\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"notebook\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"operation\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"operationParameters\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"column\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"readVersion\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"timestamp\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"txnId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"userId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"userName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "metaData",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"configuration\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"delta.autoOptimize.autoCompact\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"delta.autoOptimize.optimizeWrite\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"createdTime\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"format\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"provider\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"partitionColumns\",\"type\":{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"schemaString\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM JSON.`dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2751b3c-87e7-43b4-8568-e956d4d0b2c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## CRC files \n",
    "\n",
    "(Cyclic Redundancy Check) are used in Delta Lake for data integrity and error detection. These files are usually created alongside data files in the Delta Lake directory (in the same location as Parquet files). They help ensure that data has not been corrupted during writes, reads, or transfers by providing a checksum that can be verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e9d3082-97cd-4fd9-9bcd-849caf7b5143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>allFiles</th><th>domainMetadata</th><th>histogramOpt</th><th>metadata</th><th>numFiles</th><th>numMetadata</th><th>numProtocol</th><th>protocol</th><th>setTransactions</th><th>tableSizeBytes</th><th>txnId</th></tr></thead><tbody><tr><td>List()</td><td>List()</td><td>List(List(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), List(0, 8192, 16384, 32768, 65536, 131072, 262144, 524288, 1048576, 2097152, 4194304, 8388608, 12582912, 16777216, 20971520, 25165824, 29360128, 33554432, 37748736, 41943040, 50331648, 58720256, 67108864, 75497472, 83886080, 92274688, 100663296, 109051904, 117440512, 125829120, 130023424, 134217728, 138412032, 142606336, 146800640, 150994944, 167772160, 184549376, 201326592, 218103808, 234881024, 251658240, 268435456, 285212672, 301989888, 318767104, 335544320, 352321536, 369098752, 385875968, 402653184, 419430400, 436207616, 452984832, 469762048, 486539264, 503316480, 520093696, 536870912, 553648128, 570425344, 587202560, 603979776, 671088640, 738197504, 805306368, 872415232, 939524096, 1006632960, 1073741824, 1140850688, 1207959552, 1275068416, 1342177280, 1409286144, 1476395008, 1610612736, 1744830464, 1879048192, 2013265920, 2147483648, 2415919104, 2684354560, 2952790016, 3221225472, 3489660928, 3758096384, 4026531840, 4294967296, 8589934592, 17179869184, 34359738368, 68719476736, 137438953472, 274877906944), List(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))</td><td>List(List(false, false), 1738568356779, List(parquet), 0abc6503-7dc5-4e21-bee8-d2bf89a4804f, List(), {\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]})</td><td>0</td><td>1</td><td>1</td><td>List(1, 2)</td><td>List()</td><td>0</td><td>1a133e42-a30e-4053-930b-7d5328d24296</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [],
         [],
         [
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           8192,
           16384,
           32768,
           65536,
           131072,
           262144,
           524288,
           1048576,
           2097152,
           4194304,
           8388608,
           12582912,
           16777216,
           20971520,
           25165824,
           29360128,
           33554432,
           37748736,
           41943040,
           50331648,
           58720256,
           67108864,
           75497472,
           83886080,
           92274688,
           100663296,
           109051904,
           117440512,
           125829120,
           130023424,
           134217728,
           138412032,
           142606336,
           146800640,
           150994944,
           167772160,
           184549376,
           201326592,
           218103808,
           234881024,
           251658240,
           268435456,
           285212672,
           301989888,
           318767104,
           335544320,
           352321536,
           369098752,
           385875968,
           402653184,
           419430400,
           436207616,
           452984832,
           469762048,
           486539264,
           503316480,
           520093696,
           536870912,
           553648128,
           570425344,
           587202560,
           603979776,
           671088640,
           738197504,
           805306368,
           872415232,
           939524096,
           1006632960,
           1073741824,
           1140850688,
           1207959552,
           1275068416,
           1342177280,
           1409286144,
           1476395008,
           1610612736,
           1744830464,
           1879048192,
           2013265920,
           2147483648,
           2415919104,
           2684354560,
           2952790016,
           3221225472,
           3489660928,
           3758096384,
           4026531840,
           4294967296,
           8589934592,
           17179869184,
           34359738368,
           68719476736,
           137438953472,
           274877906944
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ],
         [
          [
           "false",
           "false"
          ],
          1738568356779,
          [
           "parquet"
          ],
          "0abc6503-7dc5-4e21-bee8-d2bf89a4804f",
          [],
          "{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
         ],
         0,
         1,
         1,
         [
          1,
          2
         ],
         [],
         0,
         "1a133e42-a30e-4053-930b-7d5328d24296"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "allFiles",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "domainMetadata",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "histogramOpt",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"fileCounts\",\"type\":{\"type\":\"array\",\"elementType\":\"long\",\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"sortedBinBoundaries\",\"type\":{\"type\":\"array\",\"elementType\":\"long\",\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"totalBytes\",\"type\":{\"type\":\"array\",\"elementType\":\"long\",\"containsNull\":true},\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "metadata",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"configuration\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"delta.autoOptimize.autoCompact\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"delta.autoOptimize.optimizeWrite\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"createdTime\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"format\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"provider\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"partitionColumns\",\"type\":{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"schemaString\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "numFiles",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "numMetadata",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "numProtocol",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "protocol",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"minReaderVersion\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"minWriterVersion\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "setTransactions",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "tableSizeBytes",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "txnId",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM JSON.`dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86c836be-b397-4168-bef5-6d6f638b624a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**DESC HISTORY** gives you a summary of table operations at the level of the table itself, but it does not expose all the detailed information thats stored in the Delta log files. The log files contain detailed JSON objects representing every individual operation, including AddFile, RemoveFile, schema changes, and even low-level details such as file paths and partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "129ea3ff-bd1b-4e04-b0b7-2a8b066da26a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>2</td><td>2025-02-03T07:39:21Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>ADD CONSTRAINT</td><td>Map(name -> Ids, expr -> id > 0 AND id < 99999999)</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>1</td><td>WriteSerializable</td><td>false</td><td>Map()</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>1</td><td>2025-02-03T07:39:19Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>CHANGE COLUMN</td><td>Map(column -> {\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":false,\"metadata\":{}})</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map()</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>0</td><td>2025-02-03T07:39:17Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>CREATE TABLE</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> false, properties -> {\"delta.autoOptimize.optimizeWrite\":\"false\",\"delta.autoOptimize.autoCompact\":\"false\"}, statsOnLoad -> false)</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map()</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2,
         "2025-02-03T07:39:21Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "ADD CONSTRAINT",
         {
          "expr": "id > 0 AND id < 99999999",
          "name": "Ids"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         1,
         "WriteSerializable",
         false,
         {},
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         1,
         "2025-02-03T07:39:19Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "CHANGE COLUMN",
         {
          "column": "{\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":false,\"metadata\":{}}"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         0,
         "WriteSerializable",
         false,
         {},
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         0,
         "2025-02-03T07:39:17Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "CREATE TABLE",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "false",
          "partitionBy": "[]",
          "properties": "{\"delta.autoOptimize.optimizeWrite\":\"false\",\"delta.autoOptimize.autoCompact\":\"false\"}",
          "statsOnLoad": "false"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         null,
         "WriteSerializable",
         true,
         {},
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobRunId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESC HISTORY demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a796e8f6-1c0b-471c-989c-1583349137b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**While DESC HISTORY** is a convenient and high-level way to view the operational history of a Delta table, the Delta log files provide:\n",
    "\n",
    "- Granular details on every individual transaction and operation.\n",
    "- Full time travel and versioning control, enabling specific snapshots of data.\n",
    "- More detailed transactional information, including file paths, partitioning, and schema changes.\n",
    "- The ability to debug and monitor operations at a very low level, which might not be possible with just DESC HISTORY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc0f472c-f201-4baa-9cc2-2c3d308d9c7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>1</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "INSERT INTO demo\n",
    "VALUES (1,True,\"Vishal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f87c6f1-3821-4235-a755-c3042d6dd1fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/</td><td>_delta_log/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet</td><td>part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet</td><td>923</td><td>1738568367000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/",
         "_delta_log/",
         0,
         0
        ],
        [
         "dbfs:/user/hive/warehouse/demo/part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet",
         "part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet",
         923,
         1738568367000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78e236bd-2fa8-4e15-a5b2-867a9ed9637e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc</td><td>00000000000000000000.crc</td><td>2131</td><td>1738568358000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json</td><td>00000000000000000000.json</td><td>1245</td><td>1738568357000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc</td><td>00000000000000000001.crc</td><td>2118</td><td>1738568360000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json</td><td>00000000000000000001.json</td><td>1052</td><td>1738568359000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc</td><td>00000000000000000002.crc</td><td>2183</td><td>1738568362000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json</td><td>00000000000000000002.json</td><td>1120</td><td>1738568361000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.crc</td><td>00000000000000000003.crc</td><td>2676</td><td>1738568369000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.json</td><td>00000000000000000003.json</td><td>1093</td><td>1738568367000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/_commits/</td><td>_commits/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc",
         "00000000000000000000.crc",
         2131,
         1738568358000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json",
         "00000000000000000000.json",
         1245,
         1738568357000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc",
         "00000000000000000001.crc",
         2118,
         1738568360000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json",
         "00000000000000000001.json",
         1052,
         1738568359000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc",
         "00000000000000000002.crc",
         2183,
         1738568362000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json",
         "00000000000000000002.json",
         1120,
         1738568361000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.crc",
         "00000000000000000003.crc",
         2676,
         1738568369000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.json",
         "00000000000000000003.json",
         1093,
         1738568367000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/_commits/",
         "_commits/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo/_delta_log/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab364748-30c7-4a22-87f1-6579c76e961e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException: [DELTA_VIOLATE_CONSTRAINT_WITH_VALUES] CHECK constraint ids ((id > 0) AND (id < 99999999)) violated by row with values:\n",
       " - id : -1\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.getConstraintViolationWithValuesException(InvariantViolationException.scala:82)\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:110)\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:121)\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException.apply(InvariantViolationException.scala)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n",
       "\tat com.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.$anonfun$doExecute$3(DeltaInvariantCheckerExec.scala:92)\n",
       "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:128)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:559)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1561)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:566)\n",
       "\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:125)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:938)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:938)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$computeOrReadCheckpoint$1(RDD.scala:413)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:410)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:377)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:82)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:82)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:224)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:199)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:161)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:134)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:155)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:102)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$10(Executor.scala:1042)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:1045)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:932)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1412)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1400)\n",
       "\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:3157)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:3138)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$6(FileFormatWriter.scala:435)\n",
       "\tat org.apache.spark.sql.catalyst.MetricKeyUtils$.measureMs(MetricKey.scala:1173)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$5(FileFormatWriter.scala:433)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:395)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:431)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$1(FileFormatWriter.scala:300)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:121)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaCommand.run(WriteIntoDeltaCommand.scala:121)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$5(commands.scala:137)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$4(commands.scala:137)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:133)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:132)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$doExecute$4(commands.scala:161)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:161)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$2(SparkPlan.scala:341)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:341)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan$.org$apache$spark$sql$execution$SparkPlan$$withExecuteQueryLogging(SparkPlan.scala:132)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:399)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:395)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:336)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:593)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:592)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$15(TransactionalWriteEdge.scala:746)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$1(TransactionalWriteEdge.scala:735)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:227)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:214)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:166)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:296)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:294)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:165)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:29)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:29)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:29)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:29)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:84)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:128)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:164)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:154)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:144)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$recordWriteFilesOperation$1(TransactionalWriteEdge.scala:365)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n",
       "\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.recordWriteFilesOperation(TransactionalWriteEdge.scala:364)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution(TransactionalWriteEdge.scala:424)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution$(TransactionalWriteEdge.scala:414)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFilesAndGetQueryExecution(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles(TransactionalWriteEdge.scala:864)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles$(TransactionalWriteEdge.scala:847)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.writeFilesWithoutClustering(ClusteredWriter.scala:962)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:151)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:119)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeFiles(WriteIntoDeltaEdge.scala:547)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:483)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:148)\n",
       "\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:280)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:135)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n",
       "\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:134)\n",
       "\tat com.databricks.sql.transaction.tahoe.catalog.WriteIntoDeltaBuilder$$anon$1$$anon$2.insert(DeltaTableV2.scala:600)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1(V1FallbackWriters.scala:108)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1$(V1FallbackWriters.scala:89)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.writeWithV1(V1FallbackWriters.scala:35)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run(V1FallbackWriters.scala:77)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run$(V1FallbackWriters.scala:76)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.run(V1FallbackWriters.scala:35)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:385)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:385)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:182)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:385)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:381)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1179)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:377)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:327)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:374)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:349)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:505)\n",
       "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:505)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:379)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:375)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:481)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:349)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:436)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:349)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:286)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:283)\n",
       "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:343)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:131)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1187)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1187)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:122)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:959)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:947)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:982)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:301)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:401)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:423)\n",
       "\tat scala.collection.immutable.List.map(List.scala:293)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:418)\n",
       "\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:40)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$33(DriverLocal.scala:1172)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:133)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$28(DriverLocal.scala:1163)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:96)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1099)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1519)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:776)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:932)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:921)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:953)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:717)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:785)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:586)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:512)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:306)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "[DELTA_VIOLATE_CONSTRAINT_WITH_VALUES] CHECK constraint ids ((id > 0) AND (id < 99999999)) violated by row with values:\n - id : -1 SQLSTATE: 23001"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "DELTA_VIOLATE_CONSTRAINT_WITH_VALUES",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": "23001",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException: [DELTA_VIOLATE_CONSTRAINT_WITH_VALUES] CHECK constraint ids ((id > 0) AND (id < 99999999)) violated by row with values:\n - id : -1\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.getConstraintViolationWithValuesException(InvariantViolationException.scala:82)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:110)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:121)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException.apply(InvariantViolationException.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat com.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.$anonfun$doExecute$3(DeltaInvariantCheckerExec.scala:92)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:128)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:559)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1561)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:566)\n\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:125)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:938)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:938)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.$anonfun$computeOrReadCheckpoint$1(RDD.scala:413)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:377)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:82)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:82)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:224)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:199)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:161)\n\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:134)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:155)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:102)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$10(Executor.scala:1042)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:1045)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:932)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1412)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1400)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:3157)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:3138)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$6(FileFormatWriter.scala:435)\n\tat org.apache.spark.sql.catalyst.MetricKeyUtils$.measureMs(MetricKey.scala:1173)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$5(FileFormatWriter.scala:433)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:395)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:431)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$1(FileFormatWriter.scala:300)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:121)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaCommand.run(WriteIntoDeltaCommand.scala:121)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$5(commands.scala:137)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$4(commands.scala:137)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:133)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:132)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$doExecute$4(commands.scala:161)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:161)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$2(SparkPlan.scala:341)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:341)\n\tat org.apache.spark.sql.execution.SparkPlan$.org$apache$spark$sql$execution$SparkPlan$$withExecuteQueryLogging(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:399)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:395)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:336)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:593)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:592)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$15(TransactionalWriteEdge.scala:746)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$1(TransactionalWriteEdge.scala:735)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:227)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:214)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:166)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:296)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:294)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:165)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:84)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:128)\n\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:164)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:154)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:144)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$recordWriteFilesOperation$1(TransactionalWriteEdge.scala:365)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.recordWriteFilesOperation(TransactionalWriteEdge.scala:364)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution(TransactionalWriteEdge.scala:424)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution$(TransactionalWriteEdge.scala:414)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFilesAndGetQueryExecution(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles(TransactionalWriteEdge.scala:864)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles$(TransactionalWriteEdge.scala:847)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.writeFilesWithoutClustering(ClusteredWriter.scala:962)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:151)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:119)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeFiles(WriteIntoDeltaEdge.scala:547)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:483)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:148)\n\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:280)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:135)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:134)\n\tat com.databricks.sql.transaction.tahoe.catalog.WriteIntoDeltaBuilder$$anon$1$$anon$2.insert(DeltaTableV2.scala:600)\n\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1(V1FallbackWriters.scala:108)\n\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1$(V1FallbackWriters.scala:89)\n\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.writeWithV1(V1FallbackWriters.scala:35)\n\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run(V1FallbackWriters.scala:77)\n\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run$(V1FallbackWriters.scala:76)\n\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.run(V1FallbackWriters.scala:35)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:385)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:385)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:182)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:385)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:381)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1179)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:377)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:327)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:374)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:349)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:505)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:505)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:379)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:375)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:481)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:349)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:436)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:349)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:286)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:283)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:343)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:131)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1187)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1187)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:122)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:959)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:947)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:982)\n\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:301)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:401)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:423)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:418)\n\tat com.databricks.backend.daemon.driver.SQLDriverLocal.repl(SQLDriverLocal.scala:40)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$33(DriverLocal.scala:1172)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:133)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$28(DriverLocal.scala:1163)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:96)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:96)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1099)\n\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1519)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:776)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:932)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:921)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:953)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:717)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:785)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:586)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:512)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:306)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "INSERT INTO demo\n",
    "VALUES (-1,True,\"Vishal\")\n",
    "--  this is an invalid entry as id is <1 \n",
    "--  so there will not be any delta log because  this is not a successfull commit , delta log is only created for the successfull commits\n",
    "\n",
    "-- also not will be shown in th DESC HISTORY demo\n",
    "\n",
    "-- parquet file may be created for this but as there is no commit no delta log will be there\n",
    "-- as delta log is single source of truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2656d8f1-d067-4fda-b06e-32e7141855ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/</td><td>_delta_log/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet</td><td>part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet</td><td>923</td><td>1738568367000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/",
         "_delta_log/",
         0,
         0
        ],
        [
         "dbfs:/user/hive/warehouse/demo/part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet",
         "part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet",
         923,
         1738568367000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf35f51f-134a-4dc5-afa1-9da9d62fe026",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>3</td><td>2025-02-03T07:39:27Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>2</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 923)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>2</td><td>2025-02-03T07:39:21Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>ADD CONSTRAINT</td><td>Map(name -> Ids, expr -> id > 0 AND id < 99999999)</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>1</td><td>WriteSerializable</td><td>false</td><td>Map()</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>1</td><td>2025-02-03T07:39:19Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>CHANGE COLUMN</td><td>Map(column -> {\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":false,\"metadata\":{}})</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map()</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>0</td><td>2025-02-03T07:39:17Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>CREATE TABLE</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> false, properties -> {\"delta.autoOptimize.optimizeWrite\":\"false\",\"delta.autoOptimize.autoCompact\":\"false\"}, statsOnLoad -> false)</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map()</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3,
         "2025-02-03T07:39:27Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         2,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "923",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         2,
         "2025-02-03T07:39:21Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "ADD CONSTRAINT",
         {
          "expr": "id > 0 AND id < 99999999",
          "name": "Ids"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         1,
         "WriteSerializable",
         false,
         {},
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         1,
         "2025-02-03T07:39:19Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "CHANGE COLUMN",
         {
          "column": "{\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":false,\"metadata\":{}}"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         0,
         "WriteSerializable",
         false,
         {},
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         0,
         "2025-02-03T07:39:17Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "CREATE TABLE",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "false",
          "partitionBy": "[]",
          "properties": "{\"delta.autoOptimize.optimizeWrite\":\"false\",\"delta.autoOptimize.autoCompact\":\"false\"}",
          "statsOnLoad": "false"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         null,
         "WriteSerializable",
         true,
         {},
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobRunId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESC HISTORY demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38851e0b-f1ad-431d-b978-92d01fc87a99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "insert multiple rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55c18546-d13c-423a-9c2e-d392ef3cc401",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>3</td><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3,
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "INSERT INTO demo \n",
    "VALUES\n",
    "(2,True,\"V\"),\n",
    "(3,True,\"I\"),\n",
    "(4,True,\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "983ad0fc-7462-4d4b-991e-2827be7f59d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/</td><td>_delta_log/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet</td><td>part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet</td><td>900</td><td>1738568380000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet</td><td>part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet</td><td>923</td><td>1738568367000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/",
         "_delta_log/",
         0,
         0
        ],
        [
         "dbfs:/user/hive/warehouse/demo/part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet",
         "part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet",
         900,
         1738568380000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet",
         "part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet",
         923,
         1738568367000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85121b4d-45ef-4635-8aa6-d7034d7be551",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc</td><td>00000000000000000000.crc</td><td>2131</td><td>1738568358000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json</td><td>00000000000000000000.json</td><td>1245</td><td>1738568357000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc</td><td>00000000000000000001.crc</td><td>2118</td><td>1738568360000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json</td><td>00000000000000000001.json</td><td>1052</td><td>1738568359000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc</td><td>00000000000000000002.crc</td><td>2183</td><td>1738568362000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json</td><td>00000000000000000002.json</td><td>1120</td><td>1738568361000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.crc</td><td>00000000000000000003.crc</td><td>2676</td><td>1738568369000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.json</td><td>00000000000000000003.json</td><td>1093</td><td>1738568367000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.crc</td><td>00000000000000000004.crc</td><td>3158</td><td>1738568382000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.json</td><td>00000000000000000004.json</td><td>1083</td><td>1738568381000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/_commits/</td><td>_commits/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc",
         "00000000000000000000.crc",
         2131,
         1738568358000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json",
         "00000000000000000000.json",
         1245,
         1738568357000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc",
         "00000000000000000001.crc",
         2118,
         1738568360000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json",
         "00000000000000000001.json",
         1052,
         1738568359000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc",
         "00000000000000000002.crc",
         2183,
         1738568362000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json",
         "00000000000000000002.json",
         1120,
         1738568361000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.crc",
         "00000000000000000003.crc",
         2676,
         1738568369000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.json",
         "00000000000000000003.json",
         1093,
         1738568367000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.crc",
         "00000000000000000004.crc",
         3158,
         1738568382000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.json",
         "00000000000000000004.json",
         1083,
         1738568381000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/_commits/",
         "_commits/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo/_delta_log/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11a22529-2e95-47c5-b0de-f18546842803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>add</th><th>commitInfo</th></tr></thead><tbody><tr><td>null</td><td>List(0203-052121-nggyovx3, Databricks-Runtime/15.4.x-scala2.12, true, WriteSerializable, List(364901121925936), WRITE, List(1, 900, 3), List(Append, [], false), 3, List(true, false), 1738568379988, db388571-ac85-495d-bc4f-fcfce652755d, 5755764547042441, inaya998877@gmail.com)</td></tr><tr><td>List(true, 1738568380000, part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet, 900, {\"numRecords\":3,\"minValues\":{\"id\":2,\"name\":\"I\"},\"maxValues\":{\"id\":4,\"name\":\"V\"},\"nullCount\":{\"id\":0,\"valid\":0,\"name\":0}}, List(1738568380000000, 1738568380000000, 1738568380000000, 268435456))</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         null,
         [
          "0203-052121-nggyovx3",
          "Databricks-Runtime/15.4.x-scala2.12",
          true,
          "WriteSerializable",
          [
           "364901121925936"
          ],
          "WRITE",
          [
           "1",
           "900",
           "3"
          ],
          [
           "Append",
           "[]",
           false
          ],
          3,
          [
           "true",
           "false"
          ],
          1738568379988,
          "db388571-ac85-495d-bc4f-fcfce652755d",
          "5755764547042441",
          "inaya998877@gmail.com"
         ]
        ],
        [
         [
          true,
          1738568380000,
          "part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet",
          900,
          "{\"numRecords\":3,\"minValues\":{\"id\":2,\"name\":\"I\"},\"maxValues\":{\"id\":4,\"name\":\"V\"},\"nullCount\":{\"id\":0,\"valid\":0,\"name\":0}}",
          [
           "1738568380000000",
           "1738568380000000",
           "1738568380000000",
           "268435456"
          ]
         ],
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "add",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"dataChange\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"modificationTime\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"path\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"size\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"stats\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"tags\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"INSERTION_TIME\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"MAX_INSERTION_TIME\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"MIN_INSERTION_TIME\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"OPTIMIZE_TARGET_SIZE\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "commitInfo",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"clusterId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"engineInfo\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"isBlindAppend\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"isolationLevel\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"notebook\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"operation\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"operationMetrics\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"numFiles\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numOutputBytes\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numOutputRows\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"operationParameters\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"mode\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"partitionBy\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"statsOnLoad\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"readVersion\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"tags\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"noRowsCopied\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"restoresDeletedRows\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"timestamp\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"txnId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"userId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"userName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT *FROM JSON.`dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.json`\n",
    "-- JSON file also computes the statistics of the data being logged in it\n",
    "-- it also contains the details of the data\n",
    "-- so while reading it can skip the parquet files \n",
    "-- ex- file1 has data having id from 1-10, file2 from 11-20,  so if u query for id=12 it can skip first file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b821fb48-f8f3-4cc1-a626-b33c0427a715",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>valid</th><th>name</th></tr></thead><tbody><tr><td>1</td><td>true</td><td>Vishal</td></tr><tr><td>2</td><td>true</td><td>V</td></tr><tr><td>3</td><td>true</td><td>I</td></tr><tr><td>4</td><td>true</td><td>S</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         true,
         "Vishal"
        ],
        [
         2,
         true,
         "V"
        ],
        [
         3,
         true,
         "I"
        ],
        [
         4,
         true,
         "S"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "valid",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d501de7-14a7-4741-baa8-3b35887f0e6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th></tr></thead><tbody><tr><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "UPDATE demo\n",
    "SET name=\"alice\"\n",
    "WHERE name='S'\n",
    "\n",
    "--  this creates new parquet file,new log file, in delta lake instead of updating the existing file it creates the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5ef4977-2ffc-4707-9a5f-d3d4b75c9184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>valid</th><th>name</th></tr></thead><tbody><tr><td>1</td><td>true</td><td>Vishal</td></tr><tr><td>2</td><td>true</td><td>V</td></tr><tr><td>3</td><td>true</td><td>I</td></tr><tr><td>4</td><td>true</td><td>alice</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         true,
         "Vishal"
        ],
        [
         2,
         true,
         "V"
        ],
        [
         3,
         true,
         "I"
        ],
        [
         4,
         true,
         "alice"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "valid",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43adae8c-28d3-47df-af9c-7c660b104552",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/</td><td>_delta_log/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/part-00000-3d4879a7-7cdd-43d3-98cb-d0fac98a477b-c000.snappy.parquet</td><td>part-00000-3d4879a7-7cdd-43d3-98cb-d0fac98a477b-c000.snappy.parquet</td><td>912</td><td>1738568386000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet</td><td>part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet</td><td>900</td><td>1738568380000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet</td><td>part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet</td><td>923</td><td>1738568367000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/",
         "_delta_log/",
         0,
         0
        ],
        [
         "dbfs:/user/hive/warehouse/demo/part-00000-3d4879a7-7cdd-43d3-98cb-d0fac98a477b-c000.snappy.parquet",
         "part-00000-3d4879a7-7cdd-43d3-98cb-d0fac98a477b-c000.snappy.parquet",
         912,
         1738568386000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet",
         "part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet",
         900,
         1738568380000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet",
         "part-00000-83272fe2-0e8d-4e40-aff1-5003ce850f4a-c000.snappy.parquet",
         923,
         1738568367000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb733a1c-053c-493a-bb15-31094992f59b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc</td><td>00000000000000000000.crc</td><td>2131</td><td>1738568358000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json</td><td>00000000000000000000.json</td><td>1245</td><td>1738568357000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc</td><td>00000000000000000001.crc</td><td>2118</td><td>1738568360000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json</td><td>00000000000000000001.json</td><td>1052</td><td>1738568359000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc</td><td>00000000000000000002.crc</td><td>2183</td><td>1738568362000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json</td><td>00000000000000000002.json</td><td>1120</td><td>1738568361000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.crc</td><td>00000000000000000003.crc</td><td>2676</td><td>1738568369000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.json</td><td>00000000000000000003.json</td><td>1093</td><td>1738568367000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.crc</td><td>00000000000000000004.crc</td><td>3158</td><td>1738568382000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.json</td><td>00000000000000000004.json</td><td>1083</td><td>1738568381000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.crc</td><td>00000000000000000005.crc</td><td>3162</td><td>1738568388000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.json</td><td>00000000000000000005.json</td><td>1759</td><td>1738568386000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/_commits/</td><td>_commits/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc",
         "00000000000000000000.crc",
         2131,
         1738568358000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json",
         "00000000000000000000.json",
         1245,
         1738568357000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc",
         "00000000000000000001.crc",
         2118,
         1738568360000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json",
         "00000000000000000001.json",
         1052,
         1738568359000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc",
         "00000000000000000002.crc",
         2183,
         1738568362000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json",
         "00000000000000000002.json",
         1120,
         1738568361000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.crc",
         "00000000000000000003.crc",
         2676,
         1738568369000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.json",
         "00000000000000000003.json",
         1093,
         1738568367000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.crc",
         "00000000000000000004.crc",
         3158,
         1738568382000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.json",
         "00000000000000000004.json",
         1083,
         1738568381000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.crc",
         "00000000000000000005.crc",
         3162,
         1738568388000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.json",
         "00000000000000000005.json",
         1759,
         1738568386000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/_commits/",
         "_commits/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo/_delta_log/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa9b78e-7d07-4877-b812-bcf1f3a1782f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>add</th><th>commitInfo</th><th>remove</th></tr></thead><tbody><tr><td>null</td><td>List(0203-052121-nggyovx3, Databricks-Runtime/15.4.x-scala2.12, false, WriteSerializable, List(364901121925936), UPDATE, List(1148, 912, 0, 1, 2, 0, 0, 0, 900, 1, 1, 741, 407), List([\"(name#118173 = S)\"]), 4, List(false, false, false), 1738568385316, 5d7517a8-4a13-4b55-b270-67904c8cf985, 5755764547042441, inaya998877@gmail.com)</td><td>null</td></tr><tr><td>null</td><td>null</td><td>List(true, 1738568385314, true, part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet, 900, {\"numRecords\":3}, List(1738568380000000, 1738568380000000, 1738568380000000, 268435456))</td></tr><tr><td>List(true, 1738568386000, part-00000-3d4879a7-7cdd-43d3-98cb-d0fac98a477b-c000.snappy.parquet, 912, {\"numRecords\":3,\"minValues\":{\"id\":2,\"name\":\"I\"},\"maxValues\":{\"id\":4,\"name\":\"alice\"},\"nullCount\":{\"id\":0,\"valid\":0,\"name\":0}}, List(1738568380000000, 1738568380000000, 1738568380000000, 268435456))</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         null,
         [
          "0203-052121-nggyovx3",
          "Databricks-Runtime/15.4.x-scala2.12",
          false,
          "WriteSerializable",
          [
           "364901121925936"
          ],
          "UPDATE",
          [
           "1148",
           "912",
           "0",
           "1",
           "2",
           "0",
           "0",
           "0",
           "900",
           "1",
           "1",
           "741",
           "407"
          ],
          [
           "[\"(name#118173 = S)\"]"
          ],
          4,
          [
           "false",
           "false",
           "false"
          ],
          1738568385316,
          "5d7517a8-4a13-4b55-b270-67904c8cf985",
          "5755764547042441",
          "inaya998877@gmail.com"
         ],
         null
        ],
        [
         null,
         null,
         [
          true,
          1738568385314,
          true,
          "part-00000-5411419c-bed0-4186-84bb-46586a0e418e-c000.snappy.parquet",
          900,
          "{\"numRecords\":3}",
          [
           "1738568380000000",
           "1738568380000000",
           "1738568380000000",
           "268435456"
          ]
         ]
        ],
        [
         [
          true,
          1738568386000,
          "part-00000-3d4879a7-7cdd-43d3-98cb-d0fac98a477b-c000.snappy.parquet",
          912,
          "{\"numRecords\":3,\"minValues\":{\"id\":2,\"name\":\"I\"},\"maxValues\":{\"id\":4,\"name\":\"alice\"},\"nullCount\":{\"id\":0,\"valid\":0,\"name\":0}}",
          [
           "1738568380000000",
           "1738568380000000",
           "1738568380000000",
           "268435456"
          ]
         ],
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "add",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"dataChange\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"modificationTime\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"path\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"size\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"stats\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"tags\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"INSERTION_TIME\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"MAX_INSERTION_TIME\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"MIN_INSERTION_TIME\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"OPTIMIZE_TARGET_SIZE\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "commitInfo",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"clusterId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"engineInfo\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"isBlindAppend\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"isolationLevel\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"notebook\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"operation\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"operationMetrics\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"executionTimeMs\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numAddedBytes\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numAddedChangeFiles\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numAddedFiles\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numCopiedRows\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numDeletionVectorsAdded\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numDeletionVectorsRemoved\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numDeletionVectorsUpdated\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numRemovedBytes\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numRemovedFiles\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"numUpdatedRows\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"rewriteTimeMs\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"scanTimeMs\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"operationParameters\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"predicate\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"readVersion\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"tags\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"delta.rowTracking.preserved\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"noRowsCopied\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"restoresDeletedRows\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}},{\"name\":\"timestamp\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"txnId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"userId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"userName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "remove",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"dataChange\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"deletionTimestamp\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"extendedFileMetadata\",\"type\":\"boolean\",\"nullable\":true,\"metadata\":{}},{\"name\":\"path\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"size\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"stats\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"tags\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"INSERTION_TIME\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"MAX_INSERTION_TIME\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"MIN_INSERTION_TIME\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"OPTIMIZE_TARGET_SIZE\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM JSON.`dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61ffe4e0-1d7d-4282-af4d-b76ae11ba538",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Delta lake operation flow (File Skipping)**\n",
    "- IN delta lake it when we do query , \n",
    "- it doesnt directly jump into parquet files and search the data\n",
    "- instead what it do, it goes to delta_log where all the details are there like insert,update,delete...\n",
    "- i will give the file which you are querying for istead of going through all files,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12a706f5-b9ac-4d0d-bb2c-2ede56fefc1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Delete the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "105376db-fed2-4a46-b64c-1f20e7628659",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th></tr></thead><tbody><tr><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DELETE FROM demo\n",
    "WHERE name='alice'\n",
    "-- this will not create any new parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fb8dc83-3f91-4dcd-bf17-f16e10a0cb31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Merge Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef84257-51de-44b4-9e1d-9a6351888267",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>valid</th><th>name</th></tr></thead><tbody><tr><td>1</td><td>true</td><td>Vishal</td></tr><tr><td>2</td><td>true</td><td>V</td></tr><tr><td>3</td><td>true</td><td>I</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         true,
         "Vishal"
        ],
        [
         2,
         true,
         "V"
        ],
        [
         3,
         true,
         "I"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "valid",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93c77778-bf9b-4aa9-9f91-e5f05f7405b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%python\n",
    "dbutils.fs.rm(\"dbfs:/user/hive/warehouse/demo_updates\", True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "780cca0c-cfdf-4207-a678-a4e3b96037fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>valid</th><th>name</th><th>operation</th></tr></thead><tbody><tr><td>3</td><td>true</td><td>Ray</td><td></td></tr><tr><td>4</td><td>true</td><td>Mikki</td><td></td></tr><tr><td>2</td><td>false</td><td>V</td><td>delete</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3,
         true,
         "Ray",
         ""
        ],
        [
         4,
         true,
         "Mikki",
         ""
        ],
        [
         2,
         false,
         "V",
         "delete"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "valid",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS demo_updates;\n",
    "CREATE OR REPLACE TABLE demo_updates (id INT, valid BOOLEAN, name STRING, operation STRING);\n",
    "INSERT INTO demo_updates VALUES (3,True,\"Ray\",\"\"),(4,True,\"Mikki\",\"\"),(2,False,\"V\",\"delete\");\n",
    "\n",
    "SELECT * FROM demo_updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2464274-8c70-4220-aa7d-2f441ad37b01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**MERGE INTO**\n",
    "through merge into query we can insert,delete,update the data at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "631a7051-82eb-47ba-a309-828046b8c705",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_updated_rows</th><th>num_deleted_rows</th><th>num_inserted_rows</th></tr></thead><tbody><tr><td>3</td><td>1</td><td>1</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3,
         1,
         1,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_updated_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_deleted_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "MERGE INTO demo\n",
    "USING demo_updates\n",
    "ON demo.id=demo_updates.id\n",
    "WHEN MATCHED AND demo_updates.operation='delete' THEN\n",
    "  DELETE\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET demo.valid= demo_updates.valid, demo.name=demo_updates.name\n",
    "WHEN NOT MATCHED THEN \n",
    "  INSERT (id, valid, name) VALUES (demo_updates.id, demo_updates.valid, demo_updates.name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "186cda16-c683-4596-8a4d-e2db0ee4b34e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>valid</th><th>name</th></tr></thead><tbody><tr><td>1</td><td>true</td><td>Vishal</td></tr><tr><td>3</td><td>true</td><td>Ray</td></tr><tr><td>4</td><td>true</td><td>Mikki</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         true,
         "Vishal"
        ],
        [
         3,
         true,
         "Ray"
        ],
        [
         4,
         true,
         "Mikki"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "valid",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40046839-49bf-4557-9a25-6d55c2ce4f3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>7</td><td>2025-02-03T07:40:01Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>MERGE</td><td>Map(predicate -> [\"(id#120583 = id#120586)\"], matchedPredicates -> [{\"predicate\":\"(operation#120589 = delete)\",\"actionType\":\"delete\"},{\"actionType\":\"update\"}], statsOnLoad -> false, notMatchedBySourcePredicates -> [], notMatchedPredicates -> [{\"actionType\":\"insert\"}])</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>6</td><td>WriteSerializable</td><td>false</td><td>Map(numTargetRowsCopied -> 0, numTargetRowsDeleted -> 1, numTargetFilesAdded -> 1, numTargetBytesAdded -> 909, numTargetBytesRemoved -> 891, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 1, executionTimeMs -> 2581, materializeSourceTimeMs -> 10, numTargetRowsInserted -> 1, numTargetRowsMatchedDeleted -> 1, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 1161, numTargetRowsUpdated -> 1, numOutputRows -> 2, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 3, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 1263)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>6</td><td>2025-02-03T07:39:52Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>DELETE</td><td>Map(predicate -> [\"(name#118928 = alice)\"])</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>5</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 912, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 965, numDeletionVectorsUpdated -> 0, numDeletedRows -> 1, scanTimeMs -> 483, numAddedFiles -> 1, numAddedBytes -> 891, rewriteTimeMs -> 482)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>5</td><td>2025-02-03T07:39:46Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>UPDATE</td><td>Map(predicate -> [\"(name#118173 = S)\"])</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>4</td><td>WriteSerializable</td><td>false</td><td>Map(numRemovedFiles -> 1, numRemovedBytes -> 900, numCopiedRows -> 2, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1148, numDeletionVectorsUpdated -> 0, scanTimeMs -> 407, numAddedFiles -> 1, numUpdatedRows -> 1, numAddedBytes -> 912, rewriteTimeMs -> 741)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>4</td><td>2025-02-03T07:39:41Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>3</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 3, numOutputBytes -> 900)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>3</td><td>2025-02-03T07:39:27Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>WRITE</td><td>Map(mode -> Append, statsOnLoad -> false, partitionBy -> [])</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>2</td><td>WriteSerializable</td><td>true</td><td>Map(numFiles -> 1, numOutputRows -> 1, numOutputBytes -> 923)</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>2</td><td>2025-02-03T07:39:21Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>ADD CONSTRAINT</td><td>Map(name -> Ids, expr -> id > 0 AND id < 99999999)</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>1</td><td>WriteSerializable</td><td>false</td><td>Map()</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>1</td><td>2025-02-03T07:39:19Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>CHANGE COLUMN</td><td>Map(column -> {\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":false,\"metadata\":{}})</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>0</td><td>WriteSerializable</td><td>false</td><td>Map()</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr><tr><td>0</td><td>2025-02-03T07:39:17Z</td><td>5755764547042441</td><td>inaya998877@gmail.com</td><td>CREATE TABLE</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> false, properties -> {\"delta.autoOptimize.optimizeWrite\":\"false\",\"delta.autoOptimize.autoCompact\":\"false\"}, statsOnLoad -> false)</td><td>null</td><td>List(364901121925936)</td><td>0203-052121-nggyovx3</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map()</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         7,
         "2025-02-03T07:40:01Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "MERGE",
         {
          "matchedPredicates": "[{\"predicate\":\"(operation#120589 = delete)\",\"actionType\":\"delete\"},{\"actionType\":\"update\"}]",
          "notMatchedBySourcePredicates": "[]",
          "notMatchedPredicates": "[{\"actionType\":\"insert\"}]",
          "predicate": "[\"(id#120583 = id#120586)\"]",
          "statsOnLoad": "false"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         6,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "2581",
          "materializeSourceTimeMs": "10",
          "numOutputRows": "2",
          "numSourceRows": "3",
          "numTargetBytesAdded": "909",
          "numTargetBytesRemoved": "891",
          "numTargetChangeFilesAdded": "0",
          "numTargetDeletionVectorsAdded": "0",
          "numTargetDeletionVectorsRemoved": "0",
          "numTargetDeletionVectorsUpdated": "0",
          "numTargetFilesAdded": "1",
          "numTargetFilesRemoved": "1",
          "numTargetRowsCopied": "0",
          "numTargetRowsDeleted": "1",
          "numTargetRowsInserted": "1",
          "numTargetRowsMatchedDeleted": "1",
          "numTargetRowsMatchedUpdated": "1",
          "numTargetRowsNotMatchedBySourceDeleted": "0",
          "numTargetRowsNotMatchedBySourceUpdated": "0",
          "numTargetRowsUpdated": "1",
          "rewriteTimeMs": "1263",
          "scanTimeMs": "1161"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         6,
         "2025-02-03T07:39:52Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "DELETE",
         {
          "predicate": "[\"(name#118928 = alice)\"]"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         5,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "965",
          "numAddedBytes": "891",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletedRows": "1",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "912",
          "numRemovedFiles": "1",
          "rewriteTimeMs": "482",
          "scanTimeMs": "483"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         5,
         "2025-02-03T07:39:46Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "UPDATE",
         {
          "predicate": "[\"(name#118173 = S)\"]"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         4,
         "WriteSerializable",
         false,
         {
          "executionTimeMs": "1148",
          "numAddedBytes": "912",
          "numAddedChangeFiles": "0",
          "numAddedFiles": "1",
          "numCopiedRows": "2",
          "numDeletionVectorsAdded": "0",
          "numDeletionVectorsRemoved": "0",
          "numDeletionVectorsUpdated": "0",
          "numRemovedBytes": "900",
          "numRemovedFiles": "1",
          "numUpdatedRows": "1",
          "rewriteTimeMs": "741",
          "scanTimeMs": "407"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         4,
         "2025-02-03T07:39:41Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         3,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "900",
          "numOutputRows": "3"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         3,
         "2025-02-03T07:39:27Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "WRITE",
         {
          "mode": "Append",
          "partitionBy": "[]",
          "statsOnLoad": "false"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         2,
         "WriteSerializable",
         true,
         {
          "numFiles": "1",
          "numOutputBytes": "923",
          "numOutputRows": "1"
         },
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         2,
         "2025-02-03T07:39:21Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "ADD CONSTRAINT",
         {
          "expr": "id > 0 AND id < 99999999",
          "name": "Ids"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         1,
         "WriteSerializable",
         false,
         {},
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         1,
         "2025-02-03T07:39:19Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "CHANGE COLUMN",
         {
          "column": "{\"name\":\"valid\",\"type\":\"boolean\",\"nullable\":false,\"metadata\":{}}"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         0,
         "WriteSerializable",
         false,
         {},
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ],
        [
         0,
         "2025-02-03T07:39:17Z",
         "5755764547042441",
         "inaya998877@gmail.com",
         "CREATE TABLE",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "false",
          "partitionBy": "[]",
          "properties": "{\"delta.autoOptimize.optimizeWrite\":\"false\",\"delta.autoOptimize.autoCompact\":\"false\"}",
          "statsOnLoad": "false"
         },
         null,
         [
          "364901121925936"
         ],
         "0203-052121-nggyovx3",
         null,
         "WriteSerializable",
         true,
         {},
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobRunId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESC HISTORY demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92a8d96c-7299-4e51-9c1a-c48a4ce0fbc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**checkpointing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37ae7dfb-f655-4208-93c0-6db900e3c302",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Its not always that delta_log will be kept in json files only,\n",
    "- its because if we create delta_log json file for every new operation there will be massive number of json files\n",
    "- and all the operation to read all those json files by the databrick apache would take a lot of time,\n",
    "to address that issue we have checkpoints.\n",
    "\n",
    "- checkpoints are being created after some points in parquet format so that read becomes faster from the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1030c86e-887f-46b1-ad3e-147e6df0cdbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc</td><td>00000000000000000000.crc</td><td>2131</td><td>1738568358000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json</td><td>00000000000000000000.json</td><td>1245</td><td>1738568357000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc</td><td>00000000000000000001.crc</td><td>2118</td><td>1738568360000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json</td><td>00000000000000000001.json</td><td>1052</td><td>1738568359000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc</td><td>00000000000000000002.crc</td><td>2183</td><td>1738568362000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json</td><td>00000000000000000002.json</td><td>1120</td><td>1738568361000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.crc</td><td>00000000000000000003.crc</td><td>2676</td><td>1738568369000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.json</td><td>00000000000000000003.json</td><td>1093</td><td>1738568367000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.crc</td><td>00000000000000000004.crc</td><td>3158</td><td>1738568382000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.json</td><td>00000000000000000004.json</td><td>1083</td><td>1738568381000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.crc</td><td>00000000000000000005.crc</td><td>3162</td><td>1738568388000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.json</td><td>00000000000000000005.json</td><td>1759</td><td>1738568386000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000006.crc</td><td>00000000000000000006.crc</td><td>3158</td><td>1738568394000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000006.json</td><td>00000000000000000006.json</td><td>1758</td><td>1738568392000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000007.crc</td><td>00000000000000000007.crc</td><td>3164</td><td>1738568403000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000007.json</td><td>00000000000000000007.json</td><td>2348</td><td>1738568401000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/_commits/</td><td>_commits/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc",
         "00000000000000000000.crc",
         2131,
         1738568358000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json",
         "00000000000000000000.json",
         1245,
         1738568357000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc",
         "00000000000000000001.crc",
         2118,
         1738568360000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json",
         "00000000000000000001.json",
         1052,
         1738568359000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc",
         "00000000000000000002.crc",
         2183,
         1738568362000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json",
         "00000000000000000002.json",
         1120,
         1738568361000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.crc",
         "00000000000000000003.crc",
         2676,
         1738568369000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.json",
         "00000000000000000003.json",
         1093,
         1738568367000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.crc",
         "00000000000000000004.crc",
         3158,
         1738568382000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.json",
         "00000000000000000004.json",
         1083,
         1738568381000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.crc",
         "00000000000000000005.crc",
         3162,
         1738568388000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.json",
         "00000000000000000005.json",
         1759,
         1738568386000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000006.crc",
         "00000000000000000006.crc",
         3158,
         1738568394000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000006.json",
         "00000000000000000006.json",
         1758,
         1738568392000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000007.crc",
         "00000000000000000007.crc",
         3164,
         1738568403000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000007.json",
         "00000000000000000007.json",
         2348,
         1738568401000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/_commits/",
         "_commits/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo/_delta_log/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3ac2257-cec1-414f-b785-342b128b7448",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "ALTER TABLE demo SET TBLPROPERTIES (\"delta.checkpointInterval\" = \"10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4948ebd4-e854-4c07-9622-1a95bfefa2b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "for x in range(1,101):\n",
    "    query= f'''\n",
    "        INSERT INTO demo VALUES ({x},true,'name{x}')\n",
    "    '''\n",
    "    spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07df110d-2c22-4e4d-9299-a8dd54c66363",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>valid</th><th>name</th></tr></thead><tbody><tr><td>100</td><td>true</td><td>name100</td></tr><tr><td>40</td><td>true</td><td>name40</td></tr><tr><td>69</td><td>true</td><td>name69</td></tr><tr><td>92</td><td>true</td><td>name92</td></tr><tr><td>44</td><td>true</td><td>name44</td></tr><tr><td>29</td><td>true</td><td>name29</td></tr><tr><td>41</td><td>true</td><td>name41</td></tr><tr><td>30</td><td>true</td><td>name30</td></tr><tr><td>56</td><td>true</td><td>name56</td></tr><tr><td>11</td><td>true</td><td>name11</td></tr><tr><td>46</td><td>true</td><td>name46</td></tr><tr><td>32</td><td>true</td><td>name32</td></tr><tr><td>43</td><td>true</td><td>name43</td></tr><tr><td>19</td><td>true</td><td>name19</td></tr><tr><td>82</td><td>true</td><td>name82</td></tr><tr><td>66</td><td>true</td><td>name66</td></tr><tr><td>36</td><td>true</td><td>name36</td></tr><tr><td>47</td><td>true</td><td>name47</td></tr><tr><td>25</td><td>true</td><td>name25</td></tr><tr><td>34</td><td>true</td><td>name34</td></tr><tr><td>58</td><td>true</td><td>name58</td></tr><tr><td>64</td><td>true</td><td>name64</td></tr><tr><td>88</td><td>true</td><td>name88</td></tr><tr><td>53</td><td>true</td><td>name53</td></tr><tr><td>21</td><td>true</td><td>name21</td></tr><tr><td>35</td><td>true</td><td>name35</td></tr><tr><td>22</td><td>true</td><td>name22</td></tr><tr><td>57</td><td>true</td><td>name57</td></tr><tr><td>18</td><td>true</td><td>name18</td></tr><tr><td>31</td><td>true</td><td>name31</td></tr><tr><td>65</td><td>true</td><td>name65</td></tr><tr><td>77</td><td>true</td><td>name77</td></tr><tr><td>42</td><td>true</td><td>name42</td></tr><tr><td>1</td><td>true</td><td>Vishal</td></tr><tr><td>38</td><td>true</td><td>name38</td></tr><tr><td>59</td><td>true</td><td>name59</td></tr><tr><td>81</td><td>true</td><td>name81</td></tr><tr><td>45</td><td>true</td><td>name45</td></tr><tr><td>90</td><td>true</td><td>name90</td></tr><tr><td>78</td><td>true</td><td>name78</td></tr><tr><td>52</td><td>true</td><td>name52</td></tr><tr><td>54</td><td>true</td><td>name54</td></tr><tr><td>12</td><td>true</td><td>name12</td></tr><tr><td>49</td><td>true</td><td>name49</td></tr><tr><td>37</td><td>true</td><td>name37</td></tr><tr><td>10</td><td>true</td><td>name10</td></tr><tr><td>61</td><td>true</td><td>name61</td></tr><tr><td>48</td><td>true</td><td>name48</td></tr><tr><td>89</td><td>true</td><td>name89</td></tr><tr><td>39</td><td>true</td><td>name39</td></tr><tr><td>85</td><td>true</td><td>name85</td></tr><tr><td>62</td><td>true</td><td>name62</td></tr><tr><td>23</td><td>true</td><td>name23</td></tr><tr><td>13</td><td>true</td><td>name13</td></tr><tr><td>55</td><td>true</td><td>name55</td></tr><tr><td>50</td><td>true</td><td>name50</td></tr><tr><td>17</td><td>true</td><td>name17</td></tr><tr><td>76</td><td>true</td><td>name76</td></tr><tr><td>71</td><td>true</td><td>name71</td></tr><tr><td>27</td><td>true</td><td>name27</td></tr><tr><td>74</td><td>true</td><td>name74</td></tr><tr><td>60</td><td>true</td><td>name60</td></tr><tr><td>15</td><td>true</td><td>name15</td></tr><tr><td>75</td><td>true</td><td>name75</td></tr><tr><td>68</td><td>true</td><td>name68</td></tr><tr><td>70</td><td>true</td><td>name70</td></tr><tr><td>86</td><td>true</td><td>name86</td></tr><tr><td>72</td><td>true</td><td>name72</td></tr><tr><td>16</td><td>true</td><td>name16</td></tr><tr><td>87</td><td>true</td><td>name87</td></tr><tr><td>83</td><td>true</td><td>name83</td></tr><tr><td>26</td><td>true</td><td>name26</td></tr><tr><td>93</td><td>true</td><td>name93</td></tr><tr><td>94</td><td>true</td><td>name94</td></tr><tr><td>95</td><td>true</td><td>name95</td></tr><tr><td>96</td><td>true</td><td>name96</td></tr><tr><td>97</td><td>true</td><td>name97</td></tr><tr><td>98</td><td>true</td><td>name98</td></tr><tr><td>99</td><td>true</td><td>name99</td></tr><tr><td>28</td><td>true</td><td>name28</td></tr><tr><td>51</td><td>true</td><td>name51</td></tr><tr><td>14</td><td>true</td><td>name14</td></tr><tr><td>33</td><td>true</td><td>name33</td></tr><tr><td>24</td><td>true</td><td>name24</td></tr><tr><td>67</td><td>true</td><td>name67</td></tr><tr><td>79</td><td>true</td><td>name79</td></tr><tr><td>63</td><td>true</td><td>name63</td></tr><tr><td>73</td><td>true</td><td>name73</td></tr><tr><td>84</td><td>true</td><td>name84</td></tr><tr><td>20</td><td>true</td><td>name20</td></tr><tr><td>80</td><td>true</td><td>name80</td></tr><tr><td>91</td><td>true</td><td>name91</td></tr><tr><td>6</td><td>true</td><td>name6</td></tr><tr><td>9</td><td>true</td><td>name9</td></tr><tr><td>7</td><td>true</td><td>name7</td></tr><tr><td>1</td><td>true</td><td>name1</td></tr><tr><td>4</td><td>true</td><td>name4</td></tr><tr><td>2</td><td>true</td><td>name2</td></tr><tr><td>8</td><td>true</td><td>name8</td></tr><tr><td>3</td><td>true</td><td>name3</td></tr><tr><td>5</td><td>true</td><td>name5</td></tr><tr><td>3</td><td>true</td><td>Ray</td></tr><tr><td>4</td><td>true</td><td>Mikki</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         100,
         true,
         "name100"
        ],
        [
         40,
         true,
         "name40"
        ],
        [
         69,
         true,
         "name69"
        ],
        [
         92,
         true,
         "name92"
        ],
        [
         44,
         true,
         "name44"
        ],
        [
         29,
         true,
         "name29"
        ],
        [
         41,
         true,
         "name41"
        ],
        [
         30,
         true,
         "name30"
        ],
        [
         56,
         true,
         "name56"
        ],
        [
         11,
         true,
         "name11"
        ],
        [
         46,
         true,
         "name46"
        ],
        [
         32,
         true,
         "name32"
        ],
        [
         43,
         true,
         "name43"
        ],
        [
         19,
         true,
         "name19"
        ],
        [
         82,
         true,
         "name82"
        ],
        [
         66,
         true,
         "name66"
        ],
        [
         36,
         true,
         "name36"
        ],
        [
         47,
         true,
         "name47"
        ],
        [
         25,
         true,
         "name25"
        ],
        [
         34,
         true,
         "name34"
        ],
        [
         58,
         true,
         "name58"
        ],
        [
         64,
         true,
         "name64"
        ],
        [
         88,
         true,
         "name88"
        ],
        [
         53,
         true,
         "name53"
        ],
        [
         21,
         true,
         "name21"
        ],
        [
         35,
         true,
         "name35"
        ],
        [
         22,
         true,
         "name22"
        ],
        [
         57,
         true,
         "name57"
        ],
        [
         18,
         true,
         "name18"
        ],
        [
         31,
         true,
         "name31"
        ],
        [
         65,
         true,
         "name65"
        ],
        [
         77,
         true,
         "name77"
        ],
        [
         42,
         true,
         "name42"
        ],
        [
         1,
         true,
         "Vishal"
        ],
        [
         38,
         true,
         "name38"
        ],
        [
         59,
         true,
         "name59"
        ],
        [
         81,
         true,
         "name81"
        ],
        [
         45,
         true,
         "name45"
        ],
        [
         90,
         true,
         "name90"
        ],
        [
         78,
         true,
         "name78"
        ],
        [
         52,
         true,
         "name52"
        ],
        [
         54,
         true,
         "name54"
        ],
        [
         12,
         true,
         "name12"
        ],
        [
         49,
         true,
         "name49"
        ],
        [
         37,
         true,
         "name37"
        ],
        [
         10,
         true,
         "name10"
        ],
        [
         61,
         true,
         "name61"
        ],
        [
         48,
         true,
         "name48"
        ],
        [
         89,
         true,
         "name89"
        ],
        [
         39,
         true,
         "name39"
        ],
        [
         85,
         true,
         "name85"
        ],
        [
         62,
         true,
         "name62"
        ],
        [
         23,
         true,
         "name23"
        ],
        [
         13,
         true,
         "name13"
        ],
        [
         55,
         true,
         "name55"
        ],
        [
         50,
         true,
         "name50"
        ],
        [
         17,
         true,
         "name17"
        ],
        [
         76,
         true,
         "name76"
        ],
        [
         71,
         true,
         "name71"
        ],
        [
         27,
         true,
         "name27"
        ],
        [
         74,
         true,
         "name74"
        ],
        [
         60,
         true,
         "name60"
        ],
        [
         15,
         true,
         "name15"
        ],
        [
         75,
         true,
         "name75"
        ],
        [
         68,
         true,
         "name68"
        ],
        [
         70,
         true,
         "name70"
        ],
        [
         86,
         true,
         "name86"
        ],
        [
         72,
         true,
         "name72"
        ],
        [
         16,
         true,
         "name16"
        ],
        [
         87,
         true,
         "name87"
        ],
        [
         83,
         true,
         "name83"
        ],
        [
         26,
         true,
         "name26"
        ],
        [
         93,
         true,
         "name93"
        ],
        [
         94,
         true,
         "name94"
        ],
        [
         95,
         true,
         "name95"
        ],
        [
         96,
         true,
         "name96"
        ],
        [
         97,
         true,
         "name97"
        ],
        [
         98,
         true,
         "name98"
        ],
        [
         99,
         true,
         "name99"
        ],
        [
         28,
         true,
         "name28"
        ],
        [
         51,
         true,
         "name51"
        ],
        [
         14,
         true,
         "name14"
        ],
        [
         33,
         true,
         "name33"
        ],
        [
         24,
         true,
         "name24"
        ],
        [
         67,
         true,
         "name67"
        ],
        [
         79,
         true,
         "name79"
        ],
        [
         63,
         true,
         "name63"
        ],
        [
         73,
         true,
         "name73"
        ],
        [
         84,
         true,
         "name84"
        ],
        [
         20,
         true,
         "name20"
        ],
        [
         80,
         true,
         "name80"
        ],
        [
         91,
         true,
         "name91"
        ],
        [
         6,
         true,
         "name6"
        ],
        [
         9,
         true,
         "name9"
        ],
        [
         7,
         true,
         "name7"
        ],
        [
         1,
         true,
         "name1"
        ],
        [
         4,
         true,
         "name4"
        ],
        [
         2,
         true,
         "name2"
        ],
        [
         8,
         true,
         "name8"
        ],
        [
         3,
         true,
         "name3"
        ],
        [
         5,
         true,
         "name5"
        ],
        [
         3,
         true,
         "Ray"
        ],
        [
         4,
         true,
         "Mikki"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "valid",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41ca74e6-f6ea-4b86-9518-417395b9aede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc</td><td>00000000000000000000.crc</td><td>2131</td><td>1738568358000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json</td><td>00000000000000000000.json</td><td>1245</td><td>1738568357000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc</td><td>00000000000000000001.crc</td><td>2118</td><td>1738568360000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json</td><td>00000000000000000001.json</td><td>1052</td><td>1738568359000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc</td><td>00000000000000000002.crc</td><td>2183</td><td>1738568362000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json</td><td>00000000000000000002.json</td><td>1120</td><td>1738568361000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.crc</td><td>00000000000000000003.crc</td><td>2676</td><td>1738568369000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.json</td><td>00000000000000000003.json</td><td>1093</td><td>1738568367000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.crc</td><td>00000000000000000004.crc</td><td>3158</td><td>1738568382000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.json</td><td>00000000000000000004.json</td><td>1083</td><td>1738568381000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.crc</td><td>00000000000000000005.crc</td><td>3162</td><td>1738568388000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.json</td><td>00000000000000000005.json</td><td>1759</td><td>1738568386000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000006.crc</td><td>00000000000000000006.crc</td><td>3158</td><td>1738568394000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000006.json</td><td>00000000000000000006.json</td><td>1758</td><td>1738568392000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000007.crc</td><td>00000000000000000007.crc</td><td>3164</td><td>1738568403000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000007.json</td><td>00000000000000000007.json</td><td>2348</td><td>1738568401000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000008.crc</td><td>00000000000000000008.crc</td><td>3196</td><td>1738568408000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000008.json</td><td>00000000000000000008.json</td><td>1103</td><td>1738568407000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000009.crc</td><td>00000000000000000009.crc</td><td>3684</td><td>1738568411000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000009.json</td><td>00000000000000000009.json</td><td>1091</td><td>1738568409000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000010.checkpoint.parquet</td><td>00000000000000000010.checkpoint.parquet</td><td>20888</td><td>1738568413000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000010.crc</td><td>00000000000000000010.crc</td><td>4172</td><td>1738568412000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000010.json</td><td>00000000000000000010.json</td><td>1091</td><td>1738568411000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000011.crc</td><td>00000000000000000011.crc</td><td>4660</td><td>1738568417000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000011.json</td><td>00000000000000000011.json</td><td>1092</td><td>1738568415000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000012.crc</td><td>00000000000000000012.crc</td><td>5148</td><td>1738568420000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000012.json</td><td>00000000000000000012.json</td><td>1092</td><td>1738568418000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000013.crc</td><td>00000000000000000013.crc</td><td>5636</td><td>1738568422000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000013.json</td><td>00000000000000000013.json</td><td>1092</td><td>1738568420000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000014.crc</td><td>00000000000000000014.crc</td><td>6124</td><td>1738568423000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000014.json</td><td>00000000000000000014.json</td><td>1092</td><td>1738568422000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000015.crc</td><td>00000000000000000015.crc</td><td>6612</td><td>1738568426000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000015.json</td><td>00000000000000000015.json</td><td>1092</td><td>1738568424000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000016.crc</td><td>00000000000000000016.crc</td><td>7102</td><td>1738568428000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000016.json</td><td>00000000000000000016.json</td><td>1092</td><td>1738568427000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000017.crc</td><td>00000000000000000017.crc</td><td>7592</td><td>1738568430000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000017.json</td><td>00000000000000000017.json</td><td>1092</td><td>1738568429000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000018.crc</td><td>00000000000000000018.crc</td><td>8084</td><td>1738568432000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000018.json</td><td>00000000000000000018.json</td><td>1096</td><td>1738568430000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000019.crc</td><td>00000000000000000019.crc</td><td>8576</td><td>1738568434000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000019.json</td><td>00000000000000000019.json</td><td>1096</td><td>1738568433000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000020.checkpoint.parquet</td><td>00000000000000000020.checkpoint.parquet</td><td>21945</td><td>1738568437000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000020.crc</td><td>00000000000000000020.crc</td><td>9068</td><td>1738568436000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000020.json</td><td>00000000000000000020.json</td><td>1096</td><td>1738568435000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000021.crc</td><td>00000000000000000021.crc</td><td>9560</td><td>1738568441000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000021.json</td><td>00000000000000000021.json</td><td>1096</td><td>1738568439000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000022.crc</td><td>00000000000000000022.crc</td><td>10052</td><td>1738568442000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000022.json</td><td>00000000000000000022.json</td><td>1096</td><td>1738568441000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000023.crc</td><td>00000000000000000023.crc</td><td>10544</td><td>1738568444000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000023.json</td><td>00000000000000000023.json</td><td>1096</td><td>1738568443000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000024.crc</td><td>00000000000000000024.crc</td><td>11036</td><td>1738568447000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000024.json</td><td>00000000000000000024.json</td><td>1096</td><td>1738568445000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000025.crc</td><td>00000000000000000025.crc</td><td>11528</td><td>1738568449000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000025.json</td><td>00000000000000000025.json</td><td>1096</td><td>1738568448000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000026.crc</td><td>00000000000000000026.crc</td><td>12020</td><td>1738568451000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000026.json</td><td>00000000000000000026.json</td><td>1096</td><td>1738568450000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000027.crc</td><td>00000000000000000027.crc</td><td>12512</td><td>1738568453000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000027.json</td><td>00000000000000000027.json</td><td>1096</td><td>1738568451000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000028.crc</td><td>00000000000000000028.crc</td><td>13004</td><td>1738568456000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000028.json</td><td>00000000000000000028.json</td><td>1096</td><td>1738568454000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000029.crc</td><td>00000000000000000029.crc</td><td>13496</td><td>1738568457000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000029.json</td><td>00000000000000000029.json</td><td>1096</td><td>1738568456000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000030.checkpoint.parquet</td><td>00000000000000000030.checkpoint.parquet</td><td>22913</td><td>1738568460000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000030.crc</td><td>00000000000000000030.crc</td><td>13988</td><td>1738568459000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000030.json</td><td>00000000000000000030.json</td><td>1096</td><td>1738568458000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000031.crc</td><td>00000000000000000031.crc</td><td>14480</td><td>1738568464000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000031.json</td><td>00000000000000000031.json</td><td>1096</td><td>1738568462000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000032.crc</td><td>00000000000000000032.crc</td><td>14972</td><td>1738568465000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000032.json</td><td>00000000000000000032.json</td><td>1096</td><td>1738568464000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000033.crc</td><td>00000000000000000033.crc</td><td>15464</td><td>1738568468000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000033.json</td><td>00000000000000000033.json</td><td>1096</td><td>1738568466000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000034.crc</td><td>00000000000000000034.crc</td><td>15956</td><td>1738568470000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000034.json</td><td>00000000000000000034.json</td><td>1096</td><td>1738568469000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000035.crc</td><td>00000000000000000035.crc</td><td>16448</td><td>1738568472000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000035.json</td><td>00000000000000000035.json</td><td>1096</td><td>1738568470000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000036.crc</td><td>00000000000000000036.crc</td><td>16940</td><td>1738568474000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000036.json</td><td>00000000000000000036.json</td><td>1096</td><td>1738568472000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000037.crc</td><td>00000000000000000037.crc</td><td>17432</td><td>1738568476000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000037.json</td><td>00000000000000000037.json</td><td>1096</td><td>1738568475000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000038.crc</td><td>00000000000000000038.crc</td><td>17924</td><td>1738568478000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000038.json</td><td>00000000000000000038.json</td><td>1096</td><td>1738568477000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000039.crc</td><td>00000000000000000039.crc</td><td>18416</td><td>1738568480000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000039.json</td><td>00000000000000000039.json</td><td>1096</td><td>1738568479000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000040.checkpoint.parquet</td><td>00000000000000000040.checkpoint.parquet</td><td>23869</td><td>1738568483000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000040.crc</td><td>00000000000000000040.crc</td><td>18908</td><td>1738568483000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000040.json</td><td>00000000000000000040.json</td><td>1096</td><td>1738568481000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000041.crc</td><td>00000000000000000041.crc</td><td>19400</td><td>1738568486000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000041.json</td><td>00000000000000000041.json</td><td>1096</td><td>1738568485000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000042.crc</td><td>00000000000000000042.crc</td><td>19892</td><td>1738568489000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000042.json</td><td>00000000000000000042.json</td><td>1096</td><td>1738568487000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000043.crc</td><td>00000000000000000043.crc</td><td>20384</td><td>1738568491000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000043.json</td><td>00000000000000000043.json</td><td>1096</td><td>1738568490000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000044.crc</td><td>00000000000000000044.crc</td><td>20876</td><td>1738568493000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000044.json</td><td>00000000000000000044.json</td><td>1096</td><td>1738568491000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000045.crc</td><td>00000000000000000045.crc</td><td>21368</td><td>1738568495000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000045.json</td><td>00000000000000000045.json</td><td>1096</td><td>1738568493000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000046.crc</td><td>00000000000000000046.crc</td><td>21860</td><td>1738568497000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000046.json</td><td>00000000000000000046.json</td><td>1096</td><td>1738568496000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000047.crc</td><td>00000000000000000047.crc</td><td>22352</td><td>1738568499000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000047.json</td><td>00000000000000000047.json</td><td>1096</td><td>1738568497000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000048.crc</td><td>00000000000000000048.crc</td><td>22844</td><td>1738568501000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000048.json</td><td>00000000000000000048.json</td><td>1096</td><td>1738568499000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000049.crc</td><td>00000000000000000049.crc</td><td>23336</td><td>1738568503000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000049.json</td><td>00000000000000000049.json</td><td>1096</td><td>1738568502000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000050.checkpoint.parquet</td><td>00000000000000000050.checkpoint.parquet</td><td>24826</td><td>1738568505000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000050.crc</td><td>00000000000000000050.crc</td><td>23828</td><td>1738568505000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000050.json</td><td>00000000000000000050.json</td><td>1096</td><td>1738568504000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000051.crc</td><td>00000000000000000051.crc</td><td>24320</td><td>1738568509000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000051.json</td><td>00000000000000000051.json</td><td>1096</td><td>1738568508000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000052.crc</td><td>00000000000000000052.crc</td><td>24812</td><td>1738568511000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000052.json</td><td>00000000000000000052.json</td><td>1096</td><td>1738568510000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000053.crc</td><td>00000000000000000053.crc</td><td>25304</td><td>1738568513000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000053.json</td><td>00000000000000000053.json</td><td>1096</td><td>1738568511000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000054.crc</td><td>00000000000000000054.crc</td><td>25796</td><td>1738568515000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000054.json</td><td>00000000000000000054.json</td><td>1096</td><td>1738568513000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000055.crc</td><td>00000000000000000055.crc</td><td>26288</td><td>1738568517000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000055.json</td><td>00000000000000000055.json</td><td>1096</td><td>1738568516000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000056.crc</td><td>00000000000000000056.crc</td><td>26780</td><td>1738568519000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000056.json</td><td>00000000000000000056.json</td><td>1096</td><td>1738568518000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000057.crc</td><td>00000000000000000057.crc</td><td>2211</td><td>1738568521000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000057.json</td><td>00000000000000000057.json</td><td>1096</td><td>1738568519000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000058.crc</td><td>00000000000000000058.crc</td><td>2211</td><td>1738568523000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000058.json</td><td>00000000000000000058.json</td><td>1096</td><td>1738568522000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000059.crc</td><td>00000000000000000059.crc</td><td>2211</td><td>1738568525000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000059.json</td><td>00000000000000000059.json</td><td>1096</td><td>1738568524000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000060.checkpoint.parquet</td><td>00000000000000000060.checkpoint.parquet</td><td>25767</td><td>1738568527000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000060.crc</td><td>00000000000000000060.crc</td><td>2211</td><td>1738568526000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000060.json</td><td>00000000000000000060.json</td><td>1096</td><td>1738568525000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000061.crc</td><td>00000000000000000061.crc</td><td>2211</td><td>1738568530000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000061.json</td><td>00000000000000000061.json</td><td>1096</td><td>1738568529000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000062.crc</td><td>00000000000000000062.crc</td><td>2211</td><td>1738568532000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000062.json</td><td>00000000000000000062.json</td><td>1096</td><td>1738568531000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000063.crc</td><td>00000000000000000063.crc</td><td>2211</td><td>1738568533000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000063.json</td><td>00000000000000000063.json</td><td>1096</td><td>1738568532000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000064.crc</td><td>00000000000000000064.crc</td><td>2211</td><td>1738568536000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000064.json</td><td>00000000000000000064.json</td><td>1096</td><td>1738568534000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000065.crc</td><td>00000000000000000065.crc</td><td>2211</td><td>1738568538000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000065.json</td><td>00000000000000000065.json</td><td>1096</td><td>1738568536000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000066.crc</td><td>00000000000000000066.crc</td><td>2211</td><td>1738568539000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000066.json</td><td>00000000000000000066.json</td><td>1096</td><td>1738568538000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000067.crc</td><td>00000000000000000067.crc</td><td>2211</td><td>1738568541000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000067.json</td><td>00000000000000000067.json</td><td>1096</td><td>1738568540000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000068.crc</td><td>00000000000000000068.crc</td><td>2211</td><td>1738568543000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000068.json</td><td>00000000000000000068.json</td><td>1096</td><td>1738568541000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000069.crc</td><td>00000000000000000069.crc</td><td>2211</td><td>1738568545000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000069.json</td><td>00000000000000000069.json</td><td>1096</td><td>1738568544000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000070.checkpoint.parquet</td><td>00000000000000000070.checkpoint.parquet</td><td>26929</td><td>1738568547000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000070.crc</td><td>00000000000000000070.crc</td><td>2211</td><td>1738568547000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000070.json</td><td>00000000000000000070.json</td><td>1096</td><td>1738568545000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000071.crc</td><td>00000000000000000071.crc</td><td>2211</td><td>1738568551000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000071.json</td><td>00000000000000000071.json</td><td>1096</td><td>1738568550000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000072.crc</td><td>00000000000000000072.crc</td><td>2211</td><td>1738568553000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000072.json</td><td>00000000000000000072.json</td><td>1096</td><td>1738568552000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000073.crc</td><td>00000000000000000073.crc</td><td>2211</td><td>1738568554000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000073.json</td><td>00000000000000000073.json</td><td>1096</td><td>1738568553000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000074.crc</td><td>00000000000000000074.crc</td><td>2211</td><td>1738568556000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000074.json</td><td>00000000000000000074.json</td><td>1096</td><td>1738568555000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000075.crc</td><td>00000000000000000075.crc</td><td>2211</td><td>1738568558000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000075.json</td><td>00000000000000000075.json</td><td>1096</td><td>1738568556000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000076.crc</td><td>00000000000000000076.crc</td><td>2211</td><td>1738568560000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000076.json</td><td>00000000000000000076.json</td><td>1096</td><td>1738568559000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000077.crc</td><td>00000000000000000077.crc</td><td>2211</td><td>1738568561000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000077.json</td><td>00000000000000000077.json</td><td>1096</td><td>1738568560000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000078.crc</td><td>00000000000000000078.crc</td><td>2211</td><td>1738568563000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000078.json</td><td>00000000000000000078.json</td><td>1096</td><td>1738568562000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000079.crc</td><td>00000000000000000079.crc</td><td>2211</td><td>1738568565000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000079.json</td><td>00000000000000000079.json</td><td>1096</td><td>1738568564000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000080.checkpoint.parquet</td><td>00000000000000000080.checkpoint.parquet</td><td>27964</td><td>1738568567000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000080.crc</td><td>00000000000000000080.crc</td><td>2211</td><td>1738568567000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000080.json</td><td>00000000000000000080.json</td><td>1096</td><td>1738568566000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000081.crc</td><td>00000000000000000081.crc</td><td>2211</td><td>1738568571000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000081.json</td><td>00000000000000000081.json</td><td>1096</td><td>1738568569000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000082.crc</td><td>00000000000000000082.crc</td><td>2211</td><td>1738568573000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000082.json</td><td>00000000000000000082.json</td><td>1096</td><td>1738568572000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000083.crc</td><td>00000000000000000083.crc</td><td>2211</td><td>1738568574000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000083.json</td><td>00000000000000000083.json</td><td>1096</td><td>1738568573000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000084.crc</td><td>00000000000000000084.crc</td><td>2211</td><td>1738568576000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000084.json</td><td>00000000000000000084.json</td><td>1096</td><td>1738568575000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000085.crc</td><td>00000000000000000085.crc</td><td>2211</td><td>1738568578000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000085.json</td><td>00000000000000000085.json</td><td>1096</td><td>1738568576000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000086.crc</td><td>00000000000000000086.crc</td><td>2211</td><td>1738568580000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000086.json</td><td>00000000000000000086.json</td><td>1096</td><td>1738568579000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000087.crc</td><td>00000000000000000087.crc</td><td>2211</td><td>1738568581000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000087.json</td><td>00000000000000000087.json</td><td>1096</td><td>1738568580000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000088.crc</td><td>00000000000000000088.crc</td><td>2211</td><td>1738568584000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000088.json</td><td>00000000000000000088.json</td><td>1096</td><td>1738568582000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000089.crc</td><td>00000000000000000089.crc</td><td>2211</td><td>1738568586000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000089.json</td><td>00000000000000000089.json</td><td>1096</td><td>1738568584000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000090.checkpoint.parquet</td><td>00000000000000000090.checkpoint.parquet</td><td>28854</td><td>1738568588000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000090.crc</td><td>00000000000000000090.crc</td><td>2211</td><td>1738568588000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000090.json</td><td>00000000000000000090.json</td><td>1096</td><td>1738568586000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000091.crc</td><td>00000000000000000091.crc</td><td>2211</td><td>1738568591000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000091.json</td><td>00000000000000000091.json</td><td>1096</td><td>1738568590000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000092.crc</td><td>00000000000000000092.crc</td><td>2211</td><td>1738568594000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000092.json</td><td>00000000000000000092.json</td><td>1096</td><td>1738568592000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000093.crc</td><td>00000000000000000093.crc</td><td>2211</td><td>1738568595000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000093.json</td><td>00000000000000000093.json</td><td>1096</td><td>1738568594000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000094.crc</td><td>00000000000000000094.crc</td><td>2211</td><td>1738568597000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000094.json</td><td>00000000000000000094.json</td><td>1096</td><td>1738568596000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000095.crc</td><td>00000000000000000095.crc</td><td>2211</td><td>1738568598000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000095.json</td><td>00000000000000000095.json</td><td>1096</td><td>1738568597000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000096.crc</td><td>00000000000000000096.crc</td><td>2211</td><td>1738568601000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000096.json</td><td>00000000000000000096.json</td><td>1096</td><td>1738568599000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000097.crc</td><td>00000000000000000097.crc</td><td>2211</td><td>1738568602000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000097.json</td><td>00000000000000000097.json</td><td>1096</td><td>1738568601000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000098.crc</td><td>00000000000000000098.crc</td><td>2211</td><td>1738568604000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000098.json</td><td>00000000000000000098.json</td><td>1096</td><td>1738568603000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000099.crc</td><td>00000000000000000099.crc</td><td>2211</td><td>1738568606000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000099.json</td><td>00000000000000000099.json</td><td>1096</td><td>1738568605000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000100.checkpoint.parquet</td><td>00000000000000000100.checkpoint.parquet</td><td>29741</td><td>1738568609000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000100.crc</td><td>00000000000000000100.crc</td><td>2211</td><td>1738568608000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000100.json</td><td>00000000000000000100.json</td><td>1096</td><td>1738568607000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000101.crc</td><td>00000000000000000101.crc</td><td>2211</td><td>1738568612000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000101.json</td><td>00000000000000000101.json</td><td>1097</td><td>1738568611000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000102.crc</td><td>00000000000000000102.crc</td><td>2211</td><td>1738568614000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000102.json</td><td>00000000000000000102.json</td><td>1097</td><td>1738568613000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000103.crc</td><td>00000000000000000103.crc</td><td>2211</td><td>1738568616000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000103.json</td><td>00000000000000000103.json</td><td>1097</td><td>1738568615000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000104.crc</td><td>00000000000000000104.crc</td><td>2211</td><td>1738568618000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000104.json</td><td>00000000000000000104.json</td><td>1097</td><td>1738568616000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000105.crc</td><td>00000000000000000105.crc</td><td>2211</td><td>1738568619000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000105.json</td><td>00000000000000000105.json</td><td>1097</td><td>1738568618000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000106.crc</td><td>00000000000000000106.crc</td><td>2213</td><td>1738568622000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000106.json</td><td>00000000000000000106.json</td><td>1097</td><td>1738568620000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000107.crc</td><td>00000000000000000107.crc</td><td>2213</td><td>1738568624000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000107.json</td><td>00000000000000000107.json</td><td>1097</td><td>1738568623000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000108.crc</td><td>00000000000000000108.crc</td><td>2213</td><td>1738568625000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000108.json</td><td>00000000000000000108.json</td><td>1101</td><td>1738568624000</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/_commits/</td><td>_commits/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/user/hive/warehouse/demo/_delta_log/_last_checkpoint</td><td>_last_checkpoint</td><td>5773</td><td>1738568609000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.crc",
         "00000000000000000000.crc",
         2131,
         1738568358000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000000.json",
         "00000000000000000000.json",
         1245,
         1738568357000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.crc",
         "00000000000000000001.crc",
         2118,
         1738568360000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000001.json",
         "00000000000000000001.json",
         1052,
         1738568359000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.crc",
         "00000000000000000002.crc",
         2183,
         1738568362000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000002.json",
         "00000000000000000002.json",
         1120,
         1738568361000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.crc",
         "00000000000000000003.crc",
         2676,
         1738568369000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000003.json",
         "00000000000000000003.json",
         1093,
         1738568367000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.crc",
         "00000000000000000004.crc",
         3158,
         1738568382000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000004.json",
         "00000000000000000004.json",
         1083,
         1738568381000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.crc",
         "00000000000000000005.crc",
         3162,
         1738568388000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000005.json",
         "00000000000000000005.json",
         1759,
         1738568386000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000006.crc",
         "00000000000000000006.crc",
         3158,
         1738568394000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000006.json",
         "00000000000000000006.json",
         1758,
         1738568392000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000007.crc",
         "00000000000000000007.crc",
         3164,
         1738568403000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000007.json",
         "00000000000000000007.json",
         2348,
         1738568401000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000008.crc",
         "00000000000000000008.crc",
         3196,
         1738568408000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000008.json",
         "00000000000000000008.json",
         1103,
         1738568407000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000009.crc",
         "00000000000000000009.crc",
         3684,
         1738568411000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000009.json",
         "00000000000000000009.json",
         1091,
         1738568409000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000010.checkpoint.parquet",
         "00000000000000000010.checkpoint.parquet",
         20888,
         1738568413000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000010.crc",
         "00000000000000000010.crc",
         4172,
         1738568412000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000010.json",
         "00000000000000000010.json",
         1091,
         1738568411000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000011.crc",
         "00000000000000000011.crc",
         4660,
         1738568417000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000011.json",
         "00000000000000000011.json",
         1092,
         1738568415000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000012.crc",
         "00000000000000000012.crc",
         5148,
         1738568420000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000012.json",
         "00000000000000000012.json",
         1092,
         1738568418000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000013.crc",
         "00000000000000000013.crc",
         5636,
         1738568422000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000013.json",
         "00000000000000000013.json",
         1092,
         1738568420000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000014.crc",
         "00000000000000000014.crc",
         6124,
         1738568423000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000014.json",
         "00000000000000000014.json",
         1092,
         1738568422000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000015.crc",
         "00000000000000000015.crc",
         6612,
         1738568426000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000015.json",
         "00000000000000000015.json",
         1092,
         1738568424000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000016.crc",
         "00000000000000000016.crc",
         7102,
         1738568428000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000016.json",
         "00000000000000000016.json",
         1092,
         1738568427000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000017.crc",
         "00000000000000000017.crc",
         7592,
         1738568430000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000017.json",
         "00000000000000000017.json",
         1092,
         1738568429000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000018.crc",
         "00000000000000000018.crc",
         8084,
         1738568432000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000018.json",
         "00000000000000000018.json",
         1096,
         1738568430000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000019.crc",
         "00000000000000000019.crc",
         8576,
         1738568434000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000019.json",
         "00000000000000000019.json",
         1096,
         1738568433000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000020.checkpoint.parquet",
         "00000000000000000020.checkpoint.parquet",
         21945,
         1738568437000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000020.crc",
         "00000000000000000020.crc",
         9068,
         1738568436000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000020.json",
         "00000000000000000020.json",
         1096,
         1738568435000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000021.crc",
         "00000000000000000021.crc",
         9560,
         1738568441000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000021.json",
         "00000000000000000021.json",
         1096,
         1738568439000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000022.crc",
         "00000000000000000022.crc",
         10052,
         1738568442000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000022.json",
         "00000000000000000022.json",
         1096,
         1738568441000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000023.crc",
         "00000000000000000023.crc",
         10544,
         1738568444000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000023.json",
         "00000000000000000023.json",
         1096,
         1738568443000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000024.crc",
         "00000000000000000024.crc",
         11036,
         1738568447000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000024.json",
         "00000000000000000024.json",
         1096,
         1738568445000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000025.crc",
         "00000000000000000025.crc",
         11528,
         1738568449000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000025.json",
         "00000000000000000025.json",
         1096,
         1738568448000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000026.crc",
         "00000000000000000026.crc",
         12020,
         1738568451000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000026.json",
         "00000000000000000026.json",
         1096,
         1738568450000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000027.crc",
         "00000000000000000027.crc",
         12512,
         1738568453000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000027.json",
         "00000000000000000027.json",
         1096,
         1738568451000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000028.crc",
         "00000000000000000028.crc",
         13004,
         1738568456000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000028.json",
         "00000000000000000028.json",
         1096,
         1738568454000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000029.crc",
         "00000000000000000029.crc",
         13496,
         1738568457000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000029.json",
         "00000000000000000029.json",
         1096,
         1738568456000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000030.checkpoint.parquet",
         "00000000000000000030.checkpoint.parquet",
         22913,
         1738568460000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000030.crc",
         "00000000000000000030.crc",
         13988,
         1738568459000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000030.json",
         "00000000000000000030.json",
         1096,
         1738568458000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000031.crc",
         "00000000000000000031.crc",
         14480,
         1738568464000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000031.json",
         "00000000000000000031.json",
         1096,
         1738568462000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000032.crc",
         "00000000000000000032.crc",
         14972,
         1738568465000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000032.json",
         "00000000000000000032.json",
         1096,
         1738568464000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000033.crc",
         "00000000000000000033.crc",
         15464,
         1738568468000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000033.json",
         "00000000000000000033.json",
         1096,
         1738568466000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000034.crc",
         "00000000000000000034.crc",
         15956,
         1738568470000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000034.json",
         "00000000000000000034.json",
         1096,
         1738568469000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000035.crc",
         "00000000000000000035.crc",
         16448,
         1738568472000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000035.json",
         "00000000000000000035.json",
         1096,
         1738568470000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000036.crc",
         "00000000000000000036.crc",
         16940,
         1738568474000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000036.json",
         "00000000000000000036.json",
         1096,
         1738568472000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000037.crc",
         "00000000000000000037.crc",
         17432,
         1738568476000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000037.json",
         "00000000000000000037.json",
         1096,
         1738568475000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000038.crc",
         "00000000000000000038.crc",
         17924,
         1738568478000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000038.json",
         "00000000000000000038.json",
         1096,
         1738568477000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000039.crc",
         "00000000000000000039.crc",
         18416,
         1738568480000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000039.json",
         "00000000000000000039.json",
         1096,
         1738568479000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000040.checkpoint.parquet",
         "00000000000000000040.checkpoint.parquet",
         23869,
         1738568483000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000040.crc",
         "00000000000000000040.crc",
         18908,
         1738568483000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000040.json",
         "00000000000000000040.json",
         1096,
         1738568481000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000041.crc",
         "00000000000000000041.crc",
         19400,
         1738568486000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000041.json",
         "00000000000000000041.json",
         1096,
         1738568485000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000042.crc",
         "00000000000000000042.crc",
         19892,
         1738568489000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000042.json",
         "00000000000000000042.json",
         1096,
         1738568487000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000043.crc",
         "00000000000000000043.crc",
         20384,
         1738568491000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000043.json",
         "00000000000000000043.json",
         1096,
         1738568490000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000044.crc",
         "00000000000000000044.crc",
         20876,
         1738568493000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000044.json",
         "00000000000000000044.json",
         1096,
         1738568491000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000045.crc",
         "00000000000000000045.crc",
         21368,
         1738568495000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000045.json",
         "00000000000000000045.json",
         1096,
         1738568493000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000046.crc",
         "00000000000000000046.crc",
         21860,
         1738568497000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000046.json",
         "00000000000000000046.json",
         1096,
         1738568496000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000047.crc",
         "00000000000000000047.crc",
         22352,
         1738568499000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000047.json",
         "00000000000000000047.json",
         1096,
         1738568497000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000048.crc",
         "00000000000000000048.crc",
         22844,
         1738568501000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000048.json",
         "00000000000000000048.json",
         1096,
         1738568499000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000049.crc",
         "00000000000000000049.crc",
         23336,
         1738568503000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000049.json",
         "00000000000000000049.json",
         1096,
         1738568502000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000050.checkpoint.parquet",
         "00000000000000000050.checkpoint.parquet",
         24826,
         1738568505000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000050.crc",
         "00000000000000000050.crc",
         23828,
         1738568505000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000050.json",
         "00000000000000000050.json",
         1096,
         1738568504000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000051.crc",
         "00000000000000000051.crc",
         24320,
         1738568509000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000051.json",
         "00000000000000000051.json",
         1096,
         1738568508000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000052.crc",
         "00000000000000000052.crc",
         24812,
         1738568511000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000052.json",
         "00000000000000000052.json",
         1096,
         1738568510000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000053.crc",
         "00000000000000000053.crc",
         25304,
         1738568513000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000053.json",
         "00000000000000000053.json",
         1096,
         1738568511000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000054.crc",
         "00000000000000000054.crc",
         25796,
         1738568515000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000054.json",
         "00000000000000000054.json",
         1096,
         1738568513000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000055.crc",
         "00000000000000000055.crc",
         26288,
         1738568517000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000055.json",
         "00000000000000000055.json",
         1096,
         1738568516000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000056.crc",
         "00000000000000000056.crc",
         26780,
         1738568519000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000056.json",
         "00000000000000000056.json",
         1096,
         1738568518000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000057.crc",
         "00000000000000000057.crc",
         2211,
         1738568521000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000057.json",
         "00000000000000000057.json",
         1096,
         1738568519000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000058.crc",
         "00000000000000000058.crc",
         2211,
         1738568523000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000058.json",
         "00000000000000000058.json",
         1096,
         1738568522000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000059.crc",
         "00000000000000000059.crc",
         2211,
         1738568525000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000059.json",
         "00000000000000000059.json",
         1096,
         1738568524000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000060.checkpoint.parquet",
         "00000000000000000060.checkpoint.parquet",
         25767,
         1738568527000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000060.crc",
         "00000000000000000060.crc",
         2211,
         1738568526000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000060.json",
         "00000000000000000060.json",
         1096,
         1738568525000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000061.crc",
         "00000000000000000061.crc",
         2211,
         1738568530000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000061.json",
         "00000000000000000061.json",
         1096,
         1738568529000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000062.crc",
         "00000000000000000062.crc",
         2211,
         1738568532000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000062.json",
         "00000000000000000062.json",
         1096,
         1738568531000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000063.crc",
         "00000000000000000063.crc",
         2211,
         1738568533000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000063.json",
         "00000000000000000063.json",
         1096,
         1738568532000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000064.crc",
         "00000000000000000064.crc",
         2211,
         1738568536000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000064.json",
         "00000000000000000064.json",
         1096,
         1738568534000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000065.crc",
         "00000000000000000065.crc",
         2211,
         1738568538000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000065.json",
         "00000000000000000065.json",
         1096,
         1738568536000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000066.crc",
         "00000000000000000066.crc",
         2211,
         1738568539000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000066.json",
         "00000000000000000066.json",
         1096,
         1738568538000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000067.crc",
         "00000000000000000067.crc",
         2211,
         1738568541000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000067.json",
         "00000000000000000067.json",
         1096,
         1738568540000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000068.crc",
         "00000000000000000068.crc",
         2211,
         1738568543000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000068.json",
         "00000000000000000068.json",
         1096,
         1738568541000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000069.crc",
         "00000000000000000069.crc",
         2211,
         1738568545000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000069.json",
         "00000000000000000069.json",
         1096,
         1738568544000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000070.checkpoint.parquet",
         "00000000000000000070.checkpoint.parquet",
         26929,
         1738568547000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000070.crc",
         "00000000000000000070.crc",
         2211,
         1738568547000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000070.json",
         "00000000000000000070.json",
         1096,
         1738568545000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000071.crc",
         "00000000000000000071.crc",
         2211,
         1738568551000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000071.json",
         "00000000000000000071.json",
         1096,
         1738568550000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000072.crc",
         "00000000000000000072.crc",
         2211,
         1738568553000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000072.json",
         "00000000000000000072.json",
         1096,
         1738568552000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000073.crc",
         "00000000000000000073.crc",
         2211,
         1738568554000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000073.json",
         "00000000000000000073.json",
         1096,
         1738568553000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000074.crc",
         "00000000000000000074.crc",
         2211,
         1738568556000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000074.json",
         "00000000000000000074.json",
         1096,
         1738568555000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000075.crc",
         "00000000000000000075.crc",
         2211,
         1738568558000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000075.json",
         "00000000000000000075.json",
         1096,
         1738568556000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000076.crc",
         "00000000000000000076.crc",
         2211,
         1738568560000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000076.json",
         "00000000000000000076.json",
         1096,
         1738568559000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000077.crc",
         "00000000000000000077.crc",
         2211,
         1738568561000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000077.json",
         "00000000000000000077.json",
         1096,
         1738568560000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000078.crc",
         "00000000000000000078.crc",
         2211,
         1738568563000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000078.json",
         "00000000000000000078.json",
         1096,
         1738568562000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000079.crc",
         "00000000000000000079.crc",
         2211,
         1738568565000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000079.json",
         "00000000000000000079.json",
         1096,
         1738568564000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000080.checkpoint.parquet",
         "00000000000000000080.checkpoint.parquet",
         27964,
         1738568567000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000080.crc",
         "00000000000000000080.crc",
         2211,
         1738568567000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000080.json",
         "00000000000000000080.json",
         1096,
         1738568566000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000081.crc",
         "00000000000000000081.crc",
         2211,
         1738568571000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000081.json",
         "00000000000000000081.json",
         1096,
         1738568569000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000082.crc",
         "00000000000000000082.crc",
         2211,
         1738568573000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000082.json",
         "00000000000000000082.json",
         1096,
         1738568572000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000083.crc",
         "00000000000000000083.crc",
         2211,
         1738568574000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000083.json",
         "00000000000000000083.json",
         1096,
         1738568573000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000084.crc",
         "00000000000000000084.crc",
         2211,
         1738568576000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000084.json",
         "00000000000000000084.json",
         1096,
         1738568575000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000085.crc",
         "00000000000000000085.crc",
         2211,
         1738568578000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000085.json",
         "00000000000000000085.json",
         1096,
         1738568576000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000086.crc",
         "00000000000000000086.crc",
         2211,
         1738568580000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000086.json",
         "00000000000000000086.json",
         1096,
         1738568579000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000087.crc",
         "00000000000000000087.crc",
         2211,
         1738568581000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000087.json",
         "00000000000000000087.json",
         1096,
         1738568580000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000088.crc",
         "00000000000000000088.crc",
         2211,
         1738568584000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000088.json",
         "00000000000000000088.json",
         1096,
         1738568582000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000089.crc",
         "00000000000000000089.crc",
         2211,
         1738568586000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000089.json",
         "00000000000000000089.json",
         1096,
         1738568584000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000090.checkpoint.parquet",
         "00000000000000000090.checkpoint.parquet",
         28854,
         1738568588000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000090.crc",
         "00000000000000000090.crc",
         2211,
         1738568588000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000090.json",
         "00000000000000000090.json",
         1096,
         1738568586000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000091.crc",
         "00000000000000000091.crc",
         2211,
         1738568591000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000091.json",
         "00000000000000000091.json",
         1096,
         1738568590000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000092.crc",
         "00000000000000000092.crc",
         2211,
         1738568594000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000092.json",
         "00000000000000000092.json",
         1096,
         1738568592000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000093.crc",
         "00000000000000000093.crc",
         2211,
         1738568595000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000093.json",
         "00000000000000000093.json",
         1096,
         1738568594000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000094.crc",
         "00000000000000000094.crc",
         2211,
         1738568597000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000094.json",
         "00000000000000000094.json",
         1096,
         1738568596000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000095.crc",
         "00000000000000000095.crc",
         2211,
         1738568598000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000095.json",
         "00000000000000000095.json",
         1096,
         1738568597000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000096.crc",
         "00000000000000000096.crc",
         2211,
         1738568601000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000096.json",
         "00000000000000000096.json",
         1096,
         1738568599000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000097.crc",
         "00000000000000000097.crc",
         2211,
         1738568602000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000097.json",
         "00000000000000000097.json",
         1096,
         1738568601000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000098.crc",
         "00000000000000000098.crc",
         2211,
         1738568604000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000098.json",
         "00000000000000000098.json",
         1096,
         1738568603000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000099.crc",
         "00000000000000000099.crc",
         2211,
         1738568606000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000099.json",
         "00000000000000000099.json",
         1096,
         1738568605000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000100.checkpoint.parquet",
         "00000000000000000100.checkpoint.parquet",
         29741,
         1738568609000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000100.crc",
         "00000000000000000100.crc",
         2211,
         1738568608000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000100.json",
         "00000000000000000100.json",
         1096,
         1738568607000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000101.crc",
         "00000000000000000101.crc",
         2211,
         1738568612000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000101.json",
         "00000000000000000101.json",
         1097,
         1738568611000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000102.crc",
         "00000000000000000102.crc",
         2211,
         1738568614000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000102.json",
         "00000000000000000102.json",
         1097,
         1738568613000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000103.crc",
         "00000000000000000103.crc",
         2211,
         1738568616000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000103.json",
         "00000000000000000103.json",
         1097,
         1738568615000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000104.crc",
         "00000000000000000104.crc",
         2211,
         1738568618000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000104.json",
         "00000000000000000104.json",
         1097,
         1738568616000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000105.crc",
         "00000000000000000105.crc",
         2211,
         1738568619000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000105.json",
         "00000000000000000105.json",
         1097,
         1738568618000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000106.crc",
         "00000000000000000106.crc",
         2213,
         1738568622000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000106.json",
         "00000000000000000106.json",
         1097,
         1738568620000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000107.crc",
         "00000000000000000107.crc",
         2213,
         1738568624000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000107.json",
         "00000000000000000107.json",
         1097,
         1738568623000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000108.crc",
         "00000000000000000108.crc",
         2213,
         1738568625000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000108.json",
         "00000000000000000108.json",
         1101,
         1738568624000
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/_commits/",
         "_commits/",
         0,
         0
        ],
        [
         "dbfs:/user/hive/warehouse/demo/_delta_log/_last_checkpoint",
         "_last_checkpoint",
         5773,
         1738568609000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/user/hive/warehouse/demo/_delta_log/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3124c25a-21e5-4e17-97e4-38a726a4dd0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "here we can see we have checkpoints files after every 10th file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96e82805-13c7-4c68-b2d3-890ef0155398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest json file:dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000108.json\nLatest parquet file: dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000100.checkpoint.parquet\n"
     ]
    }
   ],
   "source": [
    "%python\n",
    "table_path = spark.sql(\"DESC DETAIL demo\").collect()[0]['location']\n",
    "log_files  = dbutils.fs.ls(f\"{table_path}/_delta_log\")\n",
    "data_files = dbutils.fs.ls(table_path)\n",
    "\n",
    "latest_json_file = sorted([f for f in log_files if f.name.endswith('.json')],key=lambda f:f.modificationTime,\n",
    "                          reverse=True)[0].path \n",
    "\n",
    "latest_parquet_file = sorted([f for f in log_files if f.name.endswith('.parquet')],key=lambda f:f.modificationTime,\n",
    "                          reverse=True)[0].path \n",
    "\n",
    "print(f\"Latest json file:{latest_json_file}\")\n",
    "print(f\"Latest parquet file: {latest_parquet_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "037763c5-528f-493a-a558-3c52f10f2b00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "now we will try to add some data and at last the faulty data with id -1 as well and see the behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52e26f60-8372-42d5-8c3e-0df8e3928f97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2549019195061929>, line 4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,true,\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m,\u001B[38;5;241m200\u001B[39m)])\u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(-1,true,\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      2\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINSERT INTO demo VALUES \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalues\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m----> 4\u001B[0m spark\u001B[38;5;241m.\u001B[39msql(query)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1825\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1820\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   1821\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n",
       "\u001B[1;32m   1822\u001B[0m             error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINVALID_TYPE\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m   1823\u001B[0m             message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(args)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n",
       "\u001B[1;32m   1824\u001B[0m         )\n",
       "\u001B[0;32m-> 1825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jsparkSession\u001B[38;5;241m.\u001B[39msql(sqlQuery, litArgs), \u001B[38;5;28mself\u001B[39m)\n",
       "\u001B[1;32m   1826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m   1827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:255\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpy4j\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotocol\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Py4JJavaError\n",
       "\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 255\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
       "\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    257\u001B[0m     converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o384.sql.\n",
       ": com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException: [DELTA_VIOLATE_CONSTRAINT_WITH_VALUES] CHECK constraint ids ((id > 0) AND (id < 99999999)) violated by row with values:\n",
       " - id : -1\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.getConstraintViolationWithValuesException(InvariantViolationException.scala:82)\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:110)\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:121)\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException.apply(InvariantViolationException.scala)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n",
       "\tat com.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.$anonfun$doExecute$3(DeltaInvariantCheckerExec.scala:92)\n",
       "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:128)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:559)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1561)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:566)\n",
       "\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:125)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:938)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:938)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$computeOrReadCheckpoint$1(RDD.scala:413)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:410)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:377)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:82)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:82)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)\n",
       "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:224)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:199)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:161)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:134)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:155)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:102)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$10(Executor.scala:1042)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
       "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:1045)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:932)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1412)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1400)\n",
       "\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:3157)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:3138)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$6(FileFormatWriter.scala:435)\n",
       "\tat org.apache.spark.sql.catalyst.MetricKeyUtils$.measureMs(MetricKey.scala:1173)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$5(FileFormatWriter.scala:433)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:395)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:431)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$1(FileFormatWriter.scala:300)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:121)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaCommand.run(WriteIntoDeltaCommand.scala:121)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$5(commands.scala:137)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$4(commands.scala:137)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:133)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:132)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$doExecute$4(commands.scala:161)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:161)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$2(SparkPlan.scala:341)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:341)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan$.org$apache$spark$sql$execution$SparkPlan$$withExecuteQueryLogging(SparkPlan.scala:132)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:399)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:395)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:336)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:593)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:592)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$15(TransactionalWriteEdge.scala:746)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$1(TransactionalWriteEdge.scala:735)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:227)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:214)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:166)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:296)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:294)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:165)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:29)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:29)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:29)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:29)\n",
       "\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:84)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n",
       "\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n",
       "\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:128)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n",
       "\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:164)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:154)\n",
       "\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:144)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$recordWriteFilesOperation$1(TransactionalWriteEdge.scala:365)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n",
       "\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.recordWriteFilesOperation(TransactionalWriteEdge.scala:364)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution(TransactionalWriteEdge.scala:424)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution$(TransactionalWriteEdge.scala:414)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFilesAndGetQueryExecution(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles(TransactionalWriteEdge.scala:864)\n",
       "\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles$(TransactionalWriteEdge.scala:847)\n",
       "\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:181)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.writeFilesWithoutClustering(ClusteredWriter.scala:962)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:151)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:119)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeFiles(WriteIntoDeltaEdge.scala:547)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:483)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:148)\n",
       "\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:280)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:135)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n",
       "\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n",
       "\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n",
       "\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n",
       "\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:134)\n",
       "\tat com.databricks.sql.transaction.tahoe.catalog.WriteIntoDeltaBuilder$$anon$1$$anon$2.insert(DeltaTableV2.scala:600)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1(V1FallbackWriters.scala:108)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1$(V1FallbackWriters.scala:89)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.writeWithV1(V1FallbackWriters.scala:35)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run(V1FallbackWriters.scala:77)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run$(V1FallbackWriters.scala:76)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.run(V1FallbackWriters.scala:35)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:385)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:385)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:182)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:385)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:381)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1179)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:377)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:327)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:374)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:349)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:505)\n",
       "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:505)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:379)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:375)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:481)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:349)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:436)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:349)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:286)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:283)\n",
       "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:343)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:131)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1187)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1187)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:122)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:902)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:890)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:924)\n",
       "\tat sun.reflect.GeneratedMethodAccessor1105.invoke(Unknown Source)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "Py4JJavaError",
        "evalue": "An error occurred while calling o384.sql.\n: com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException: [DELTA_VIOLATE_CONSTRAINT_WITH_VALUES] CHECK constraint ids ((id > 0) AND (id < 99999999)) violated by row with values:\n - id : -1\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.getConstraintViolationWithValuesException(InvariantViolationException.scala:82)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:110)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:121)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException.apply(InvariantViolationException.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat com.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.$anonfun$doExecute$3(DeltaInvariantCheckerExec.scala:92)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:128)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:559)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1561)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:566)\n\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:125)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:938)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:938)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.$anonfun$computeOrReadCheckpoint$1(RDD.scala:413)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:377)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:82)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:82)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:224)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:199)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:161)\n\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:134)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:155)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:102)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$10(Executor.scala:1042)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:1045)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:932)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1412)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1400)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:3157)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:3138)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$6(FileFormatWriter.scala:435)\n\tat org.apache.spark.sql.catalyst.MetricKeyUtils$.measureMs(MetricKey.scala:1173)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$5(FileFormatWriter.scala:433)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:395)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:431)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$1(FileFormatWriter.scala:300)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:121)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaCommand.run(WriteIntoDeltaCommand.scala:121)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$5(commands.scala:137)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$4(commands.scala:137)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:133)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:132)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$doExecute$4(commands.scala:161)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:161)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$2(SparkPlan.scala:341)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:341)\n\tat org.apache.spark.sql.execution.SparkPlan$.org$apache$spark$sql$execution$SparkPlan$$withExecuteQueryLogging(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:399)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:395)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:336)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:593)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:592)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$15(TransactionalWriteEdge.scala:746)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$1(TransactionalWriteEdge.scala:735)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:227)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:214)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:166)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:296)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:294)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:165)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:84)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:128)\n\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:164)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:154)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:144)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$recordWriteFilesOperation$1(TransactionalWriteEdge.scala:365)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.recordWriteFilesOperation(TransactionalWriteEdge.scala:364)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution(TransactionalWriteEdge.scala:424)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution$(TransactionalWriteEdge.scala:414)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFilesAndGetQueryExecution(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles(TransactionalWriteEdge.scala:864)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles$(TransactionalWriteEdge.scala:847)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.writeFilesWithoutClustering(ClusteredWriter.scala:962)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:151)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:119)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeFiles(WriteIntoDeltaEdge.scala:547)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:483)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:148)\n\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:280)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:135)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:134)\n\tat com.databricks.sql.transaction.tahoe.catalog.WriteIntoDeltaBuilder$$anon$1$$anon$2.insert(DeltaTableV2.scala:600)\n\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1(V1FallbackWriters.scala:108)\n\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1$(V1FallbackWriters.scala:89)\n\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.writeWithV1(V1FallbackWriters.scala:35)\n\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run(V1FallbackWriters.scala:77)\n\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run$(V1FallbackWriters.scala:76)\n\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.run(V1FallbackWriters.scala:35)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:385)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:385)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:182)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:385)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:381)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1179)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:377)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:327)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:374)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:349)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:505)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:505)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:379)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:375)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:481)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:349)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:436)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:349)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:286)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:283)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:343)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:131)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1187)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1187)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:122)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:902)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:890)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:924)\n\tat sun.reflect.GeneratedMethodAccessor1105.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>Py4JJavaError</span>: An error occurred while calling o384.sql.\n: com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException: [DELTA_VIOLATE_CONSTRAINT_WITH_VALUES] CHECK constraint ids ((id > 0) AND (id < 99999999)) violated by row with values:\n - id : -1\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.getConstraintViolationWithValuesException(InvariantViolationException.scala:82)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:110)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:121)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException.apply(InvariantViolationException.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat com.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.$anonfun$doExecute$3(DeltaInvariantCheckerExec.scala:92)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:128)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:559)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1561)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:566)\n\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:125)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:938)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:938)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.$anonfun$computeOrReadCheckpoint$1(RDD.scala:413)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:377)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:82)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:82)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:224)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:199)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:161)\n\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:134)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:155)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:102)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$10(Executor.scala:1042)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:1045)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:932)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1412)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1400)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:3157)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:3138)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$6(FileFormatWriter.scala:435)\n\tat org.apache.spark.sql.catalyst.MetricKeyUtils$.measureMs(MetricKey.scala:1173)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$5(FileFormatWriter.scala:433)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:395)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:431)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$1(FileFormatWriter.scala:300)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:121)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaCommand.run(WriteIntoDeltaCommand.scala:121)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$5(commands.scala:137)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$4(commands.scala:137)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:133)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:132)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$doExecute$4(commands.scala:161)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:161)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$2(SparkPlan.scala:341)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:341)\n\tat org.apache.spark.sql.execution.SparkPlan$.org$apache$spark$sql$execution$SparkPlan$$withExecuteQueryLogging(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:399)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:395)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:336)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:593)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:592)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$15(TransactionalWriteEdge.scala:746)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$1(TransactionalWriteEdge.scala:735)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:227)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:214)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:166)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:296)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:294)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:165)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:84)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:128)\n\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:164)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:154)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:144)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$recordWriteFilesOperation$1(TransactionalWriteEdge.scala:365)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.recordWriteFilesOperation(TransactionalWriteEdge.scala:364)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution(TransactionalWriteEdge.scala:424)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution$(TransactionalWriteEdge.scala:414)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFilesAndGetQueryExecution(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles(TransactionalWriteEdge.scala:864)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles$(TransactionalWriteEdge.scala:847)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.writeFilesWithoutClustering(ClusteredWriter.scala:962)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:151)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:119)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeFiles(WriteIntoDeltaEdge.scala:547)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:483)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:148)\n\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:280)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:135)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:134)\n\tat com.databricks.sql.transaction.tahoe.catalog.WriteIntoDeltaBuilder$$anon$1$$anon$2.insert(DeltaTableV2.scala:600)\n\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1(V1FallbackWriters.scala:108)\n\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1$(V1FallbackWriters.scala:89)\n\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.writeWithV1(V1FallbackWriters.scala:35)\n\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run(V1FallbackWriters.scala:77)\n\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run$(V1FallbackWriters.scala:76)\n\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.run(V1FallbackWriters.scala:35)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:385)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:385)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:182)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:385)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:381)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1179)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:377)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:327)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:374)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:349)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:505)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:505)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:379)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:375)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:481)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:349)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:436)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:349)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:286)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:283)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:343)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:131)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1187)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1187)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:122)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:902)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:890)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:924)\n\tat sun.reflect.GeneratedMethodAccessor1105.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
        "File \u001B[0;32m<command-2549019195061929>, line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,true,\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m,\u001B[38;5;241m200\u001B[39m)])\u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(-1,true,\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINSERT INTO demo VALUES \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalues\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 4\u001B[0m spark\u001B[38;5;241m.\u001B[39msql(query)\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/session.py:1825\u001B[0m, in \u001B[0;36mSparkSession.sql\u001B[0;34m(self, sqlQuery, args, **kwargs)\u001B[0m\n\u001B[1;32m   1820\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1821\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m   1822\u001B[0m             error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mINVALID_TYPE\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1823\u001B[0m             message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(args)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[1;32m   1824\u001B[0m         )\n\u001B[0;32m-> 1825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jsparkSession\u001B[38;5;241m.\u001B[39msql(sqlQuery, litArgs), \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:255\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpy4j\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotocol\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Py4JJavaError\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 255\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39ma, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
        "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o384.sql.\n: com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException: [DELTA_VIOLATE_CONSTRAINT_WITH_VALUES] CHECK constraint ids ((id > 0) AND (id < 99999999)) violated by row with values:\n - id : -1\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.getConstraintViolationWithValuesException(InvariantViolationException.scala:82)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:110)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException$.apply(InvariantViolationException.scala:121)\n\tat com.databricks.sql.transaction.tahoe.schema.DeltaInvariantViolationException.apply(InvariantViolationException.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat com.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.$anonfun$doExecute$3(DeltaInvariantCheckerExec.scala:92)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:128)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:559)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1561)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:566)\n\tat org.apache.spark.sql.execution.datasources.WriteFilesExec.$anonfun$doExecuteWrite$1(WriteFiles.scala:125)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:938)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:938)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.$anonfun$computeOrReadCheckpoint$1(RDD.scala:413)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:377)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:82)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:82)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:224)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:199)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:161)\n\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:134)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:155)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:102)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$10(Executor.scala:1042)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:1045)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:932)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$runJob$1(DAGScheduler.scala:1412)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1400)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:3157)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:3138)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$6(FileFormatWriter.scala:435)\n\tat org.apache.spark.sql.catalyst.MetricKeyUtils$.measureMs(MetricKey.scala:1173)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeWrite$5(FileFormatWriter.scala:433)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.writeAndCommit(FileFormatWriter.scala:395)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeWrite(FileFormatWriter.scala:431)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$1(FileFormatWriter.scala:300)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:121)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaCommand.run(WriteIntoDeltaCommand.scala:121)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$5(commands.scala:137)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$sideEffectResult$4(commands.scala:137)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:133)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:132)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.$anonfun$doExecute$4(commands.scala:161)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:161)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$2(SparkPlan.scala:341)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:341)\n\tat org.apache.spark.sql.execution.SparkPlan$.org$apache$spark$sql$execution$SparkPlan$$withExecuteQueryLogging(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:399)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:395)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:336)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:593)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:592)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$15(TransactionalWriteEdge.scala:746)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$writeFilesAndGetQueryExecution$1(TransactionalWriteEdge.scala:735)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag(DeltaLogging.scala:227)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.withOperationTypeTag$(DeltaLogging.scala:214)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.withOperationTypeTag(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$2(DeltaLogging.scala:166)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile(DeltaLogging.scala:296)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordFrameProfile$(DeltaLogging.scala:294)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordFrameProfile(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.$anonfun$recordDeltaOperationInternal$1(DeltaLogging.scala:165)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperationWithResultTags(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation(DatabricksSparkUsageLogger.scala:29)\n\tat com.databricks.spark.util.PublicDBLogging.recordOperation0(DatabricksSparkUsageLogger.scala:84)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:169)\n\tat com.databricks.spark.util.UsageLogger.recordOperation(UsageLogger.scala:70)\n\tat com.databricks.spark.util.UsageLogger.recordOperation$(UsageLogger.scala:57)\n\tat com.databricks.spark.util.DatabricksSparkUsageLogger.recordOperation(DatabricksSparkUsageLogger.scala:128)\n\tat com.databricks.spark.util.UsageLogging.recordOperation(UsageLogger.scala:511)\n\tat com.databricks.spark.util.UsageLogging.recordOperation$(UsageLogger.scala:490)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordOperation(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperationInternal(DeltaLogging.scala:164)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation(DeltaLogging.scala:154)\n\tat com.databricks.sql.transaction.tahoe.metering.DeltaLogging.recordDeltaOperation$(DeltaLogging.scala:144)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.recordDeltaOperation(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.$anonfun$recordWriteFilesOperation$1(TransactionalWriteEdge.scala:365)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.recordWriteFilesOperation(TransactionalWriteEdge.scala:364)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution(TransactionalWriteEdge.scala:424)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFilesAndGetQueryExecution$(TransactionalWriteEdge.scala:414)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFilesAndGetQueryExecution(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles(TransactionalWriteEdge.scala:864)\n\tat com.databricks.sql.transaction.tahoe.files.TransactionalWriteEdge.writeFiles$(TransactionalWriteEdge.scala:847)\n\tat com.databricks.sql.transaction.tahoe.OptimisticTransaction.writeFiles(OptimisticTransaction.scala:181)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.writeFilesWithoutClustering(ClusteredWriter.scala:962)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:151)\n\tat com.databricks.sql.transaction.tahoe.commands.ClusteredWriter.run(ClusteredWriter.scala:119)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeFiles(WriteIntoDeltaEdge.scala:547)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.writeAndReturnCommitData(WriteIntoDeltaEdge.scala:483)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$2(WriteIntoDeltaEdge.scala:148)\n\tat com.databricks.sql.transaction.tahoe.DeltaLog.withNewTransaction(DeltaLog.scala:280)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.$anonfun$run$1(WriteIntoDeltaEdge.scala:135)\n\tat com.databricks.sql.acl.CheckPermissions$.$anonfun$trusted$2(CheckPermissions.scala:2307)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag(QueryTagger.scala:62)\n\tat com.databricks.sql.util.ThreadLocalTagger.withTag$(QueryTagger.scala:59)\n\tat com.databricks.sql.util.QueryTagger$.withTag(QueryTagger.scala:140)\n\tat com.databricks.sql.acl.CheckPermissions$.trusted(CheckPermissions.scala:2307)\n\tat com.databricks.sql.transaction.tahoe.commands.WriteIntoDeltaEdge.run(WriteIntoDeltaEdge.scala:134)\n\tat com.databricks.sql.transaction.tahoe.catalog.WriteIntoDeltaBuilder$$anon$1$$anon$2.insert(DeltaTableV2.scala:600)\n\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1(V1FallbackWriters.scala:108)\n\tat org.apache.spark.sql.execution.datasources.v2.SupportsV1Write.writeWithV1$(V1FallbackWriters.scala:89)\n\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.writeWithV1(V1FallbackWriters.scala:35)\n\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run(V1FallbackWriters.scala:77)\n\tat org.apache.spark.sql.execution.datasources.v2.V1FallbackWriters.run$(V1FallbackWriters.scala:76)\n\tat org.apache.spark.sql.execution.datasources.v2.AppendDataExecV1.run(V1FallbackWriters.scala:35)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:385)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:385)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:182)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:385)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:462)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:800)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:334)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:205)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:737)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:381)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1179)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:377)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:327)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:374)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:349)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:505)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:505)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:379)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:375)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:481)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:349)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:436)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:349)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:286)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:283)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:343)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:131)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1187)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1187)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:122)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:902)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:890)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:924)\n\tat sun.reflect.GeneratedMethodAccessor1105.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "\n",
    "values = \", \".join([f\"({x},true,'name{x}')\" for x in range(100,200)])+ \", \" + \"(-1,true,'error')\"\n",
    "query = f\"INSERT INTO demo VALUES {values}\"\n",
    "\n",
    "spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8be05255-5eeb-4b47-813c-c0af089eeb3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest json file:dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000108.json\nLatest parquet file: dbfs:/user/hive/warehouse/demo/_delta_log/00000000000000000100.checkpoint.parquet\n"
     ]
    }
   ],
   "source": [
    "%python\n",
    "table_path = spark.sql(\"DESC DETAIL demo\").collect()[0]['location']\n",
    "log_files  = dbutils.fs.ls(f\"{table_path}/_delta_log\")\n",
    "data_files = dbutils.fs.ls(table_path)\n",
    "\n",
    "latest_json_file = sorted([f for f in log_files if f.name.endswith('.json')],key=lambda f:f.modificationTime,\n",
    "                          reverse=True)[0].path \n",
    "\n",
    "latest_parquet_file = sorted([f for f in log_files if f.name.endswith('.parquet')],key=lambda f:f.modificationTime,\n",
    "                          reverse=True)[0].path \n",
    "\n",
    "print(f\"Latest json file:{latest_json_file}\")\n",
    "print(f\"Latest parquet file: {latest_parquet_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77ed1762-fc75-4fd4-a5ce-1206f81a2b7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "246498b1-de1c-43e3-9476-f710b28581f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3084798714853264,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "2 demo",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
